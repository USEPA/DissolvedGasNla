---
title: "Analysis of NLA17 Dissolved Gas Indicator"
authors: "J. Beaulieu, R. Martin, and M. McManus"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    fig_caption: yes
    depth: 2
    number_sections: true
    code_folding:  hide
editor_options: 
  chunk_output_type: console
---

```{r results='hide', message=FALSE, warning=FALSE}
# load libraries
library(sf) # spatial data
library(gstat) # lagged scatterplot, variogram
library(tidyverse) # dplyr, ggplot
library(janitor) # clean names
library(spdep) # k-NN and Moran plot
library(ncf) # ncf::correlogram

# Identify local path for each user
localPath <- Sys.getenv("USERPROFILE")

# Define helper functions
# standardized formatting for column names
toEPA <- function(X1){
  names(X1) = tolower(names(X1))
  names(X1) = gsub(pattern = c("\\(| |#|)|/|-|\\+|:|_"), replacement = ".", x = names(X1))
  X1
}
```


# Background
During the 2017 National Lakes Assesment, duplicate dissolved gas samples were collected at a depth of ~0.1m at the index site at each waterbody.  Gas samples were analyzed for CO~2~, CH~4~, and N~2~O concentration via gas chromatography and $\delta^{13}CO_{2}$ and $\delta^{13}CH_{4}$ via cavity ring-down spectroscopy.  The following analysis pertains to the concentration data.


## Getting data and filtering
The dissolved gas data were currated the 'NLA' dissolved gas project in RStudio.  The code can be found at a private github repository (https://github.com/USEPA/NLA).  After aggregating across duplicate samples, the data were written to nla17gasDataAggregated_2020-02-24.txt.  A copy of this data file is stored in documents library associated with the 'ORD NLA17 Dissolved Gas' Private Group on SharePoint (https://usepa.sharepoint.com/sites/ORD_NLA17_Dissolved_Gas).  This file was futher manipulated in "C://Users//JBEAULIE//OneDrive-Environmental Protection Agency (EPA)//gitRepository//DissolvedGasNla//scripts//dataMunge.Rmd" and written out as an .RData object, which is imported below.


```{r}
# Read data file 
 load(paste0(localPath,
            "/Environmental Protection Agency (EPA)/",
            "ORD NLA17 Dissolved Gas - Documents/",
            "inputData/dg.2020-11-25.RData"))

```



The data file contains `r dg %>% distinct(site.id, visit.no) %>% summarize(n = n()) %>% pull()` unique sampling trips defined by unique combinations of 'site.id' and 'visit.no'.  There were `r dg %>% distinct(site.id) %>% summarize(n = n()) %>% pull()` waterbodies sampled, `r dg %>% filter(visit.no == 2) %>% summarize(n = n()) %>% pull()` of which were sampled twice. The primary response variables are the concentrations of CO~2~, CH~4~, and N~2~O dissolved in the surface water of each waterbody.  Concentration is expressed in both mass based units (umol/L, nmol/L: dissolved.co2, dissolved.ch4, dissolved.n2o) and as a saturation ratio (co2.sat.ratio, ch4.sat.ratio, n2o.sat.ratio).  Saturation ratio is defined as the ratio of the measured concentration to that expected if the waterbody were in equilibrium with the atmosphere.  A value of 1 indicates equilibrium, values < 1 indicate undersaturation and values > 1 indicate supersaturation.  Undersaturated waterbodies function as a sink for the atmospheric gas whereas supersaturated waterbodies function as a source.


```{r}
# These are the main response variables.
dg %>% 
  select(dissolved.co2.umol, dissolved.ch4.umol, dissolved.n2o.nmol, co2.sat.ratio, ch4.sat.ratio, n2o.sat.ratio) %>%
  {summary(.)}

dg %>% 
  ggplot(aes(as.factor(x = WSA9), y = log(dissolved.n2o.nmol))) + geom_boxplot()

dg %>% 
  ggplot(aes(as.factor(x = WSA9), y = (n2o.sat.ratio))) + geom_boxplot()
```


#  Exploratory spatial analysis
## Population estimates by ecoregion
The survey design allows for population estimates of central tendency and variance by ecoregion (and other subpopulations), which can provide insight into spatial patterning.  There is broad overlap in mean +/- 95% CI estimates for dissolved CH~4~ concentration.  The Northern Plains, Temperate Plains, and Western Mountains have low dissolved CO~2~ concentration.  

```{r, fig.cap= "Fig. caption: Mean +/- 95% CI for the dissolved gas concentration indicator"}
# Read population estimates calculated with local neighborhood variance estimate provided by Tom Kincaid (12/12/2019)
pop <- read.csv(file = paste0(localPath, 
                              "/Environmental Protection Agency (EPA)/",
                              "ORD NLA17 Dissolved Gas - Documents/",
                              "inputData/populationEstimates/",
                              "NLA_2017_Percentile_Estimates_Local_Mean_20191212.csv"),
                as.is = TRUE) %>%
  toEPA()  # enforce formatting convention

# Convert units for dissolved gas concentration indicator
pop <- pop %>%
  mutate(estimate = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            estimate * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            estimate * 1000000000, # mol/L -> nmol/L for n2o
                            estimate)), # all others
         lcb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            lcb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            lcb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            lcb95pct)), # all others
         ucb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            ucb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            ucb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            ucb95pct))) # all others


# extract population estimates for ecoregion and nation
pop.eco <- pop %>% 
  filter(type %in% c("AG_ECO9_NM", "National"), # extract estimates for ecoregion and nation
         statistic == "Mean") # extract mean estimate

# extract dissolved gas indicator, order by dissolved CH4
pop.eco.diss <- pop.eco %>%
  filter(grepl("dissolved", indicator, ignore.case = TRUE)) %>%
  mutate(subpopulation = factor(subpopulation, 
                             levels = filter(pop.eco, indicator == "DISSOLVED_CH4", subpopulation != "National") %>%
                               arrange(estimate) %>%
                               select(subpopulation) %>%
                               pull() %>%
                               c("National", .)))
  
# look at dissolved concentration indicator
ggplot(pop.eco.diss, aes(estimate, subpopulation)) +
  geom_point() +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct)) +
  facet_wrap(~indicator, scales = "free_x") +
  theme(axis.title = element_blank())



# Read in file containing population estimates for N2O flux (nmol N2O m-2 day-1).
# This file was generated by running Tom Kincaid's code in scripts/CDF_Estimates_jb.Rmd
pop.n2o <- read.csv(file = paste0(localPath, 
                              "/Environmental Protection Agency (EPA)/",
                              "ORD NLA17 Dissolved Gas - Documents/",
                              "inputData/populationEstimates/",
                              "NLA_2017_Percentile_Estimates_Local_Mean_F_N2O_JB20201119.csv"),
                as.is = TRUE) %>%
  toEPA()  # enforce formatting convention

# extract population estimates for ecoregion and nation
pop.n2o <- pop.n2o %>% 
  filter(type %in% c("AG_ECO9_NM", "National"), # extract estimates for ecoregion and nation
         statistic == "Mean") %>% # extract mean estimate
   mutate(subpopulation = factor(subpopulation, 
                             levels = filter(., subpopulation != "National") %>%
                               arrange(estimate) %>%
                               select(subpopulation) %>%
                               pull() %>%
                               c("National", .)))


# look at dissolved concentration indicator
ggplot(pop.n2o, aes(estimate, subpopulation)) +
  geom_point() +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct)) +
  facet_wrap(~indicator, scales = "free_x") +
  theme(axis.title = element_blank())
  
```

Population level estimates of variance can be calculated using a simple random sample or local neighborhood estimators.  The local neighborhood estimator will yield lower variance estimates if there is spatial structure in the data.  Below are plotted the 95% confidence intervals calculated using both methods.  In nearly all cases the local neighborhood estimator yields a more restricted interval.

```{r}
# calculate 95% CI using local neighborhood estimator
pop.eco.diss <- pop.eco.diss %>%
  mutate(ci95.local = ucb95pct - lcb95pct)

# read in SRS estimator population estimates provided by Tom Kincaid (12/12/2019)
pop.srs <- read.csv(file = paste0(localPath, 
                              "/Environmental Protection Agency (EPA)/",
                              "ORD NLA17 Dissolved Gas - Documents/",
                              "inputData/populationEstimates/",
                              "NLA_2017_Percentile_Estimates_SRS_20191212.csv"),
                as.is = TRUE) %>%
  toEPA()  # enforce formatting convention

# Convert units for dissolved gas concentration indicator
pop.srs <- pop.srs %>%
  mutate(estimate = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            estimate * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            estimate * 1000000000, # mol/L -> nmol/L for n2o
                            estimate)), # all others
         lcb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            lcb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            lcb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            lcb95pct)), # all others
         ucb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            ucb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            ucb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            ucb95pct))) # all others


# extract population estimates for ecoregion and nation
# dissolved gas indicator
pop.srs.eco.diss <- pop.srs %>% 
  filter(type %in% c("AG_ECO9_NM", "National"), # extract estimates for ecoregion and nation
         statistic == "Mean") %>% # extract mean estimate
  mutate(ci95.srs = ucb95pct - lcb95pct) %>%
  filter(grepl("dissolved", indicator, ignore.case = TRUE)) 

# merge local neighborhood and SRS variance estimates
pop.local.srs <- dplyr::full_join(pop.eco.diss,
                                  select(pop.srs.eco.diss, -nresp, -estimate, 
                                         -stderror, -lcb95pct, -ucb95pct)) %>%
  select(-nresp, -estimate, -stderror, -lcb95pct, -ucb95pct) %>%
  pivot_longer(cols = starts_with("ci95"))


# look at dissolved concentration indicator
ggplot(pop.local.srs, aes(value, subpopulation)) +
  geom_point(aes(color = name)) +
  facet_wrap(~indicator, scales = "free_x") +
  xlab("95% confidence interval of mean") +
  theme(axis.title.y = element_blank())
```




## Bubble plots
Bubble plots can be used to visualize patterns in geospatial data.  In the plots below, bubble size reflects the gas concentration and color reflects saturation status (i.e. source or sink).  The code immediately below converts the dataframe to a spatial object and reads in the ecoregion ploygons.  The first bubble plot below is of dissolved CO2 which seems to show a pattern of higher concentrations along the eastern seaboard.
```{r}
# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg$map.lon.dd, latitude = dg$map.lat.dd)

dg.sf <- st_as_sf(dg, coords = c("map.lon.dd", "map.lat.dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting



# read in ecoregion polygons
ecoR <- st_read(dsn = paste0(localPath, 
                             "/Environmental Protection Agency (EPA)/",
                             "ORD NLA17 Dissolved Gas - Documents/inputData"),
                layer = "aggr_ecoregions_simple")



# "Temperate" is misspelled.
ecoR <- ecoR %>% 
  mutate(WSA9_NAME = as.character(WSA9_NAME), # conv to char
         WSA9_NAME = ifelse(WSA9_NAME == "Temporate Plains",
                            "Temperate Plains", # correct sp
                            WSA9_NAME),
         WSA9_NAME = as.factor(WSA9_NAME)) # back to factor

# Check CRS
st_crs(ecoR) # 3857
ecoR <- st_transform(ecoR, 5070) # convert to CONUS Albers
st_crs(ecoR) # 5070
```



```{r}
# CO2 Bubble plots

ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = dissolved.co2, color = co2.src.snk), 
          show.legend = "point") + # improve legend
  ggtitle("Dissolved CO2 (uM)") +
  scale_color_manual(values = c("white", "black"), name = "source/sink") +
  scale_size(name = "dissolved CO2 (uM)",
             range = c(0.1, 5), # custom size range
             breaks = c(10, 100, 300, 600)) # custom breaks
```

Spatial patterns in dissolved CH4 are not apparent, although all but two sites are supersaturated. 

```{r}
ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = dissolved.ch4, color = ch4.src.snk), 
          show.legend = "point") +
  ggtitle("Dissolved CH4 (uM)") +
  scale_color_manual(values = c("white", "black"), name = "source/sink") +
  scale_size(name = "dissolved CH4 (uM)",
             range = c(0.1, 10), # custom size range
             breaks = c(0.1, 1, 10, 50, 100)) # custom breaks
```

The prevalance of undersaturated dissolved N2O concentrations is an important finding.  The IPCC assumes surface waters are an important source of N2O to the atmosphere.   Webb et al. recently published a paper in PNAS reporting that 70 out of 101 reservoirs sampled in Saskatchewan were N2O sinks.  This paper made quite a splash.  In our study, `r sum(dg$n2o.src.snk == "sink")` out of `r sum(!is.na(dg$dissolved.n2o))` sampled waterbodies were an N2O sink. It is somewhat interesting to note that the some of the highest concentrations were observed in Indiana/Ohio, where I conducted much of my dissertation research on aquatic N2O emissions.

```{r}
ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = dissolved.n2o, color = n2o.src.snk),
          show.legend = "point") +
  ggtitle("Dissolved N2O (nM)") +
  scale_color_manual(values = c("white", "black"), name = "source/sink") +
  scale_size(name = "dissolved N2O (nM)",
             range = c(0.1, 10), # custom size range
             breaks = c(1, 10, 25, 50, 100)) # custom breaks
```

We can also look at population estimates of N2O saturation ratio by ecoregion.  Wow, despite the prevalance of N2O undersaturated waterbodies, the 95% CI for the mean N2O saturation ratio encompasses 1 in all ecoregions except the Northern Plains and Northern Appalachians. 
```{r}

# extract saturation indicator, order by n2o
pop.eco.sat <- pop.eco %>%
  filter(grepl("sat", indicator, ignore.case = TRUE)) %>%
  mutate(subpopulation = factor(subpopulation, 
                             levels = filter(pop.eco, indicator == "N2O_SAT_RATIO", subpopulation != "National") %>%
                               arrange(estimate) %>%
                               select(subpopulation) %>%
                               pull() %>%
                               c("National", .)))
  
# look at dissolved concentration indicator
ggplot(pop.eco.sat, aes(estimate, subpopulation)) +
  geom_point() +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct)) +
  facet_wrap(~indicator, scales = "free_x") +
  theme(axis.title = element_blank()) +
  geom_vline(xintercept = 1)

```

## Geopackage
Create a simple feature on entire dg data frame, then split out a simple feature, df_sf2, by filtering sample_source = DG.  The geodatabase will contain two simple features, the dissolved gas sampled points/lakes and the nine aggregated ecoregions.
```{r, geopackage, eval=FALSE, echo=FALSE,}
library(janitor) # clean_names function
names(dg)

dg_1 <- select(dg,site.id:map.lon.dd, dissolved.co2, dissolved.ch4, dissolved.n2o, co2.sat.ratio, ch4.sat.ratio, n2o.sat.ratio, WSA9, WSA9_NAME)
names(dg_1)
dg_1 <- clean_names(dg_1) %>% filter(wsa9 != "AK") %>% 
  mutate(log_n2o = round(log(dissolved_n2o),3)) %>% 
  mutate(log_n2osatratio = round(log(n2o_sat_ratio),3))
# underscores are "safer" names used in GIS

names(dg_1)
# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg_1$map_lon_dd, latitude = dg_1$map_lat_dd)

dg_sf1 <- st_as_sf(dg_1, coords = c("map_lon_dd", "map_lat_dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # 4326 is just the EPSG identifier of WGS84. WGS84 comprises a standard coordinate frame for the Earth, a datum/reference ellipsoid for raw altitude data, and a gravitational equipotential surface (the geoid) that defines the nominal sea level.  5070 is for Albers equal Area.
st_crs(dg_sf1)

dg_sf1 <- filter(dg_sf1, sample_source == "DG") # now 1184 obs vs. previously 1185 obs., why change in sample size
st_crs(dg_sf1)

# Bryan suggested EPSG 4326
# Bryan Chastain as GeoServices suggested reducing the number of fields, and I tried that but was still unable to open the geodatabase in ArcMap 
# Based on gis stackexchange I think the "." in variable names is causing the problem
# https://gis.stackexchange.com/questions/319611/arcgis-geopackage-arcmap-drawing-error?noredirect=1
# Even with change to _ still get error message about invalid coordinate system when st_transform(5070) used

# Check CRS
st_crs(ecoR)
names(ecoR)
# changed from 4326 to 5070
ecoR1 <- st_transform(ecoR, 5070) %>% 
  select(OBJECTID, WSA9, WSA9_NAME) # Grab variables of interest
st_crs(ecoR1)

# write out dg.sf and ecoR as two layers in geopackage, gpkg, geodatabase
# 74. Creating a geopackage geodatabase, then adding more layers
# https://github.com/r-spatial/sf/issues/392
# creating a _v1.gpkg having large sample size and should be in Albers
st_write(dg_sf1, dsn = file.path(getwd(), "nladg_v1.gpkg"), layer = "dg_sf1", driver = "GPKG", quiet = FALSE)
st_layers("nladg_v1.gpkg")

# N.B. b/c old layer with untransformed was already in geodatabase have to delete it and then append the new layer
st_write(dg_sf1, dsn = file.path(getwd(), "nladg_v1.gpkg"), layer = "dg_sf1", driver = "GPKG", delete_layer = TRUE, append = TRUE, quiet = FALSE)
st_layers("nla_dg1.gpkg")

# https://gis.stackexchange.com/questions/223240/writing-multiple-layers-to-geopackage-using-writeogr-in-r
st_write(ecoR1, dsn = file.path(getwd(), "nladg_v1.gpkg"), layer = "ecoR1", driver = "GPKG", append = TRUE, quiet = FALSE)
st_layers("nladg_v1.gpkg")
#CPL polygon not appearing in geopackage

names(dg_sf1)
summary(dg_sf1$dissolved_n2o) # matches Roy's stats
```

## Summarizing distances
Getting distances between sites overall and by ecoregion to help set distances for lagged scatterplots.  First, Worked out steps on a sample of NLA sites.  Could only get parts of Anna Springsteen's code to work.
```{r, eval=FALSE, echo=FALSE, distances}
names(dg.sf)
head(dg.sf$WSA9_NAME)
# distinct returns all unique geometry + attribute combinations.  convert to df if not interested in geometry
dg.sf %>% as.data.frame() %>% distinct(WSA9_NAME) 
# distinct.Spatial(dg.sf, WSA9_NAME) # this doesn't work either.
distinct(dg, WSA9_NAME)

# take a small sample of dg.sf to test getting distances
set.seed(1859)
# st_sample only returns a list of coordinates
nla_samp <- st_sample(dg.sf, 10, type = "random", exact = TRUE)
plot(nla_samp)
class(nla_samp)
head(nla_samp)

# sample_n keeps attributes and geometries
nla_samp1 <- sample_n(dg.sf, 10)
plot(nla_samp1, max.plot=1)
class(nla_samp1)
head(nla_samp1$site.id, 10)
distmat <- st_distance(nla_samp1,nla_samp1,by_element = FALSE)
class(distmat) # thought this would return matrix
max(distmat)
min(distmat)
summary(distmat) # think this returns summary of all pairwise distances on each obs, v1-v10
dim(distmat)

rdistmat <- distmat[1:10, ]
print(rdistmat)
rdistmat1 <- as.vector(rdistmat)
round(min(rdistmat1[rdistmat1!=0]))
round(quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[2])
round(median(rdistmat1[rdistmat1!=0]))
round(quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[4])
round(max(rdistmat1[rdistmat1!=0]))

names(ecoR)
class(ecoR)
# contrast ecoRname <- as.data.frame(select(ecoR,"WSA9_NAME"))
# geom is sticky with select but not pull
# ecoRname <- as.data.frame(pull(ecoR,"WSA9_NAME"))
ecoRname1 <- as.character(pull(ecoR,"WSA9_NAME")) #Springsteen code needs to be character to populate columns of matrix below
class(ecoRname1)
head(ecoRname1, 9)
# initialize summary tables
euc.summary <- matrix(NA, nrow=5, ncol=length(ecoRname1)+1) # initializing blank matrices to fill in the loop
dim(euc.summary)
colnames(euc.summary) <- c("ALL",ecoRname1) #indicates same assignment in each object
rownames(euc.summary) <- c("Min","Q1","Median","Q3","Max")
euc.summary

# Add all distances summary statistics to column 1 of the summary table (i.e. not by region)
euc.summary[,1] <- round(c( min(rdistmat1[rdistmat1!=0]), quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[2], median(rdistmat1[rdistmat1!=0]), quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[4], max(rdistmat1[rdistmat1!=0]) ),1)

print(euc.summary)

# Unsure that Springsteen function below will work as euc is an spDists created object that I think retained ecoregional & not sure that's so with rdistmat1
# Add within-region summary statistics to summary table 
for (r in 1:length(ecoRname1)){ # loop through regions and fill in the matrices
  euc.reg <- euc[grep(ecoRname1[r], rownames(euc)), grep(ecoRname1[r],colnames(euc))] # retrieving only columns and rows in the distance matrix that contain the same region code in their column/row name
  # retrieving only columns and rows in the distance matrix that contain the same region code in their column/row name
  euc.summary[, (r+1)] <- round(c( min(euc.reg[euc.reg!=0]), quantile(euc.reg[euc.reg!=0], probs=seq(0,1, 0.25), names=F)[2], median(euc.reg[euc.reg!=0]), quantile(euc.reg[euc.reg!=0], probs=seq(0,1, 0.25), names=F)[4], max(euc.reg[euc.reg!=0]) ),1)
}

# Distances for all NLA sites
distmat_dg <- st_distance(dg.sf,dg.sf,by_element = FALSE)
rdistmat_dg <- distmat_dg[1:1185, ]
rdistmat1_dg <- as.vector(rdistmat_dg)

# initialize summary tables
euc.summary_dg <- matrix(NA, nrow=5, ncol=length(ecoRname1)+1) # initializing blank matrices to fill in the loop
dim(euc.summary_dg)
colnames(euc.summary_dg) <- c("ALL",ecoRname1) #indicates same assignment in each object
rownames(euc.summary_dg) <- c("Min","Q1","Median","Q3","Max")


euc.summary_dg[,1] <- round(c( min(rdistmat1_dg[rdistmat1_dg!=0]), quantile(rdistmat1_dg[rdistmat1_dg!=0], probs=seq(0,1, 0.25), names=F)[2], median(rdistmat1_dg[rdistmat1_dg!=0]), quantile(rdistmat1_dg[rdistmat1_dg!=0], probs=seq(0,1, 0.25), names=F)[4], max(rdistmat1_dg[rdistmat1_dg!=0]) ),1)

print(euc.summary_dg)

# brute force to get 5-number summary of ecoregions cut-n-paste ecoregions to get specific data frames:  cpl, nap, npl, sap, spl, tpl, umw, wmt, xer
names(dg.sf)

count(dg.sf, WSA9_NAME) %>% print(n = Inf)

# Get ecoregion-specific NLA sites
cpl <- dg.sf %>% filter(WSA9_NAME == "Coastal Plains")

distmat_cpl <- st_distance(cpl, cpl,by_element = FALSE)
dim(distmat_cpl)
rdistmat_cpl <- distmat_cpl[1:150, ] # change to match # sites/rows
rdistmat1_cpl <- as.vector(rdistmat_cpl)

round(min(rdistmat1_cpl[rdistmat1_cpl!=0]))
round(quantile(rdistmat1_cpl[rdistmat1_cpl!=0], probs=seq(0,1, 0.25), names=F)[2])
round(median(rdistmat1_cpl[rdistmat1_cpl!=0]))
round(quantile(rdistmat1_cpl[rdistmat1_cpl!=0], probs=seq(0,1, 0.25), names=F)[4])
round(max(rdistmat1_cpl[rdistmat1_cpl!=0]))

# GitHub question:  if I save a workspace, .RData, will that be pushed when I push to GitHub?  Or, should data frames go in .gitignore?
```

## Lagged scatterplots
Note that can use simple feature object, such as cpl, for histogram, but spatial object needed for lagged scatterplots.  I took log10 transform to  get data somewhat unimodal and symmetric.
```{r, eval=FALSE, echo=FALSE, laggedscatterplot}
# cpl
cpl_sp <- as(cpl, "Spatial")
class(cpl_sp)
ggplot(cpl,aes(dissolved.ch4)) + geom_histogram()
ggplot(cpl,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.ch4~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.ch4~1, cpl_sp, c(0, 10000, 25000, 50000, 150000, 250000, 500000))

ggplot(cpl,aes(dissolved.co2)) + geom_histogram()
ggplot(cpl,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.co2~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(log10(dissolved.co2)~1, cpl_sp, c(0, 10000, 25000, 50000, 150000, 250000, 500000))

ggplot(cpl,aes(dissolved.n2o)) + geom_histogram()
ggplot(cpl,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.n2o~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(log10(dissolved.n2o)~1, cpl_sp, c(0, 10000, 25000, 50000, 150000, 250000, 500000))

# nap
nap_sp <- as(nap, "Spatial")
class(nap_sp)
ggplot(nap,aes(dissolved.ch4)) + geom_histogram()
ggplot(nap,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.ch4~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.ch4)~1, nap_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(nap,aes(dissolved.co2)) + geom_histogram()
ggplot(nap,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.co2~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.co2)~1, nap_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(nap,aes(dissolved.n2o)) + geom_histogram()
ggplot(nap,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.n2o~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.n2o)~1, nap_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

# npl
npl_sp <- as(npl, "Spatial")
class(npl_sp)
ggplot(npl,aes(dissolved.ch4)) + geom_histogram()
ggplot(npl,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.ch4~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.ch4)~1, npl_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(npl,aes(dissolved.co2)) + geom_histogram()
ggplot(npl,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.co2~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.co2)~1, npl_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(npl,aes(dissolved.n2o)) + geom_histogram()
ggplot(npl,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.n2o~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.n2o)~1, npl_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

# sap
sap_sp <- as(sap, "Spatial")
class(sap_sp)
ggplot(sap,aes(dissolved.ch4)) + geom_histogram()
ggplot(sap,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(dissolved.ch4~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(log10(dissolved.ch4)~1, sap_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(sap,aes(dissolved.co2)) + geom_histogram()
ggplot(sap,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(dissolved.co2~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(log10(dissolved.co2)~1, sap_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(sap,aes(dissolved.n2o)) + geom_histogram()
ggplot(sap,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(dissolved.n2o~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(log10(dissolved.n2o)~1, sap_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

# spl
spl_sp <- as(spl, "Spatial")
class(spl_sp)
ggplot(spl,aes(dissolved.ch4)) + geom_histogram()
ggplot(spl,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(dissolved.ch4~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(log10(dissolved.ch4)~1, spl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(spl,aes(dissolved.co2)) + geom_histogram()
ggplot(spl,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(dissolved.co2~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(log10(dissolved.co2)~1, spl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(spl,aes(dissolved.n2o)) + geom_histogram()
ggplot(spl,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(dissolved.n2o~1, spl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.n2o)~1, spl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

# tpl
tpl_sp <- as(tpl, "Spatial")
class(tpl_sp)
ggplot(tpl,aes(dissolved.ch4)) + geom_histogram()
ggplot(tpl,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(dissolved.ch4~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(log10(dissolved.ch4)~1, tpl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(tpl,aes(dissolved.co2)) + geom_histogram()
ggplot(tpl,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(dissolved.co2~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(log10(dissolved.co2)~1, tpl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(tpl,aes(dissolved.n2o)) + geom_histogram()
ggplot(tpl,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(dissolved.n2o~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(log10(dissolved.n2o)~1, tpl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

# umw
umw_sp <- as(umw, "Spatial")
class(umw_sp)
ggplot(umw,aes(dissolved.ch4)) + geom_histogram()
ggplot(umw,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, umw_sp, c(0, 10000, 50000, 75000, 100000, 200000, 350000))

hscat(dissolved.ch4~1, umw_sp, c(0, 10000, 50000, 75000, 100000, 200000, 350000))

hscat(log10(dissolved.ch4)~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

ggplot(umw,aes(dissolved.co2)) + geom_histogram()
ggplot(umw,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, umw_sp, c(0, 10000, 50000, 75000, 100000, 200000, 350000))

hscat(dissolved.co2~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

hscat(log10(dissolved.co2)~1, umw_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(umw,aes(dissolved.n2o)) + geom_histogram()
ggplot(umw,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

hscat(dissolved.n2o~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

hscat(log10(dissolved.n2o)~1, umw_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

# wmt
wmt_sp <- as(wmt, "Spatial")
class(wmt_sp)
ggplot(wmt,aes(dissolved.ch4)) + geom_histogram()
ggplot(wmt,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(dissolved.ch4~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(log10(dissolved.ch4)~1, wmt_sp, c(0, 25000, 50000, 100000, 200000, 350000, 700000))

ggplot(wmt,aes(dissolved.co2)) + geom_histogram()
ggplot(wmt,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(dissolved.co2~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(log10(dissolved.co2)~1, wmt_sp, c(0, 25000, 50000, 100000, 200000, 350000, 700000))

ggplot(wmt,aes(dissolved.n2o)) + geom_histogram()
ggplot(wmt,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(dissolved.n2o~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(log10(dissolved.n2o)~1, wmt_sp, c(0, 25000, 50000, 100000, 200000, 350000, 700000))

# xer
xer_sp <- as(xer, "Spatial")
class(xer_sp)
ggplot(xer,aes(dissolved.ch4)) + geom_histogram()
ggplot(xer,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
# 10 km bin/lag only has 2 points plotted so start with 50 km
hscat(log10(dissolved.ch4)~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(dissolved.ch4~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(log10(dissolved.ch4)~1, xer_sp, c(0, 25000, 50000, 750000, 100000, 200000, 400000, 800000))

ggplot(xer,aes(dissolved.co2)) + geom_histogram()
ggplot(xer,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(dissolved.co2~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(log10(dissolved.co2)~1, xer_sp, c(0, 25000, 50000, 750000, 100000, 200000, 400000, 800000))

ggplot(xer,aes(dissolved.n2o)) + geom_histogram()
ggplot(xer,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(dissolved.n2o~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(log10(dissolved.n2o)~1, xer_sp, c(0, 25000, 50000, 750000, 100000, 200000, 400000, 800000))

# all
dg_sp <- as(dg.sf, "Spatial")
class(dg_sp)
ggplot(dg.sf,aes(dissolved.ch4)) + geom_histogram()
ggplot(dg.sf,aes(dissolved.ch4)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4)~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(dissolved.ch4~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(log10(dissolved.ch4)~1, dg_sp, c(0, 10000, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(dg.sf,aes(dissolved.co2)) + geom_histogram()
ggplot(dg.sf,aes(dissolved.co2)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2)~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(dissolved.co2~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(log10(dissolved.co2)~1, dg_sp, c(0, 10000, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(dg.sf,aes(dissolved.n2o)) + geom_histogram()
ggplot(dg.sf,aes(dissolved.n2o)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o)~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(dissolved.n2o~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(log10(dissolved.n2o)~1, dg_sp, c(0, 10000, 25000, 50000, 100000, 200000, 300000, 400000))

```

## k-NN = 1 and Moran plots
As with the lagged scatter plots, I had to take a simple feature object and convert it to a spatial object so I could use the nearest-neighbor and Moran scatter plot functions from the spdep package.  A Moran plot is based on plotting the N~2~O variable, dissolved.n2o, of a focal point on the x-axis and the average dissolved.n2o of the neighboring points on the y-axis.  Moran scatter plots were made for each of the 9 ecoregions and 1 for all of the NLA sites.  For each plot, a neighborhood of points was defined by the maximum distance to first nearest neighbor.  A distance-based spatial relationship was used because many of the ecoregions have several non-contiguous polygons or areas, which prevents a contiguity-based spatial relationship from being used.  The slope of the line through the scatter plot of points measures spatial autocorrelation, with a positive slope indicating positive spatial autocorrelation.

The code below is to be run separately for each ecoregion.  The CPL, TPL, and UMW ecoregions show strong positive spatial autocorrelation.  Negative spatial autocorrelation occurs in the NPL ecoregion because of the maximum outlier at a South Dakota site.  The SPL and XER ecoregions show no evidence of spatial autocorrelation.  Interestingly, it appears that the ecoregions with the highest dissolved.n2o concentrations, CPL, TPL, and UMW, drive the national pattern.
```{r, knn_moran}
names(dg)
# also includ WSA9, WSA9_NAME feature
dg_1 <- select(dg,site.id:dissolved.n2o, WSA9, WSA9_NAME)
names(dg_1)
dg_1 <- clean_names(dg_1)
names(dg_1)
distinct(dg_1, wsa9)
# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg_1$map_lon_dd, latitude = dg_1$map_lat_dd)

dg_sf1 <- st_as_sf(dg_1, coords = c("map_lon_dd", "map_lat_dd"),crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting 

st_crs(dg_sf1)
glimpse(dg_sf1)
# Get ecoregion-specific NLA sites
## CPL
cpl <- dg_sf1 %>% filter(wsa9 == "CPL" & visit_no == 1 & sample_source == "DG")

cpl_sp <- as(cpl, "Spatial")
class(cpl_sp)

ds1coords <- coordinates(cpl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = cpl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=134761, row.names=cpl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(cpl_sp)
plot(ds1nb1, ds1coords, labels = cpl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(cpl)
# cpl_df <- st_drop_geometry(cpl)
# names(cpl_df)
summary(cpl$dissolved_n2o)

moran.plot(log(cpl$dissolved_n2o), listw = dsnb1.listw, labels = cpl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## NAP
nap <- dg_sf1 %>% filter(wsa9 == "NAP" & visit_no == 1 & sample_source == "DG")

nap_sp <- as(nap, "Spatial")
class(nap_sp)

ds1coords <- coordinates(nap_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = nap_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=112630, row.names=nap_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(nap_sp)
plot(ds1nb1, ds1coords, labels = nap_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(nap)
# nap_df <- st_drop_geometry(nap)
# names(nap_df)
summary(nap$dissolved_n2o)

moran.plot(log(nap$dissolved_n2o), listw = dsnb1.listw, labels = nap$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## NPL
npl <- dg_sf1 %>% filter(wsa9 == "NPL" & visit_no == 1 & sample_source == "DG")

npl_sp <- as(npl, "Spatial")
class(npl_sp)

ds1coords <- coordinates(npl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = npl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=215395, row.names=npl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(npl_sp)
plot(ds1nb1, ds1coords, labels = npl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(npl)
# npl_df <- st_drop_geometry(npl)
# names(npl_df)
summary(npl$dissolved_n2o)

moran.plot(log(npl$dissolved_n2o), listw = dsnb1.listw, labels = npl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## SAP
sap <- dg_sf1 %>% filter(wsa9 == "SAP" & visit_no == 1 & sample_source == "DG")

sap_sp <- as(sap, "Spatial")
class(sap_sp)

ds1coords <- coordinates(sap_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = sap_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=128285, row.names=sap_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(sap_sp)
plot(ds1nb1, ds1coords, labels = sap_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(sap)
# sap_df <- st_drop_geometry(sap)
# names(sap_df)
summary(sap$dissolved_n2o)

moran.plot(log(sap$dissolved_n2o), listw = dsnb1.listw, labels = sap$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## SPL
spl <- dg_sf1 %>% filter(wsa9 == "SPL" & visit_no == 1 & sample_source == "DG")

spl_sp <- as(spl, "Spatial")
class(spl_sp)

ds1coords <- coordinates(spl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = spl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=173395, row.names=spl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(spl_sp)
plot(ds1nb1, ds1coords, labels = spl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(spl)
# spl_df <- st_drop_geometry(spl)
# names(spl_df)
summary(spl$dissolved_n2o)

moran.plot(log(spl$dissolved_n2o), listw = dsnb1.listw, labels = spl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## TPL
tpl <- dg_sf1 %>% filter(wsa9 == "TPL" & visit_no == 1 & sample_source == "DG")

tpl_sp <- as(tpl, "Spatial")
class(tpl_sp)
nrow(zerodist(tpl_sp)) # indicates 1 pair of identical coordinates

(zerodist(tpl_sp)) # this gives the row numbers of the pair 30 & 36
View(tpl) # to view rows 30, site_id NLA17_IN-10002, & 36, NLA17_IN-10047

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(tpl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = tpl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=223893, row.names=tpl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(tpl_sp)
plot(ds1nb1, ds1coords, labels = tpl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(tpl)
# tpl_df <- st_drop_geometry(tpl)
# names(tpl_df)
summary(tpl$dissolved_n2o)

moran.plot(log(tpl$dissolved_n2o), listw = dsnb1.listw, labels = tpl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## UMW
umw <- dg_sf1 %>% filter(wsa9 == "UMW" & visit_no == 1 & sample_source == "DG")

umw_sp <- as(umw, "Spatial")
class(umw_sp)
nrow(zerodist(umw_sp)) # indicates 1 pair of identical coordinates

(zerodist(umw_sp)) # this gives the row numbers of the pair 136 & 158
View(umw) # to view rows 136, site_id NLA17_WI-10027, & 158, NLA17_WI-10127

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(umw_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = umw_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=99590, row.names=umw_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(umw_sp)
plot(ds1nb1, ds1coords, labels = umw_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(umw)
# umw_df <- st_drop_geometry(umw)
# names(umw_df)
summary(umw$dissolved_n2o)

moran.plot(log(umw$dissolved_n2o), listw = dsnb1.listw, labels = umw$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## WMT
wmt <- dg_sf1 %>% filter(wsa9 == "WMT" & visit_no == 1 & sample_source == "DG")

wmt_sp <- as(wmt, "Spatial")
class(wmt_sp)

# nrow(zerodist(wmt_sp)) # indicates 1 pair of identical coordinates
# (zerodist(wmt_sp)) # this gives the row numbers of the pair 136 & 158
# View(wmt) # to view rows 136, site_id NLA17_WI-10027, & 158, NLA17_WI-10127

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(wmt_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = wmt_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=295987, row.names=wmt_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(wmt_sp)
plot(ds1nb1, ds1coords, labels = wmt_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(wmt)
# wmt_df <- st_drop_geometry(wmt)
# names(wmt_df)
summary(wmt$dissolved_n2o)

moran.plot(log(wmt$dissolved_n2o), listw = dsnb1.listw, labels = wmt$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## XER
xer <- dg_sf1 %>% filter(wsa9 == "XER" & visit_no == 1 & sample_source == "DG")

xer_sp <- as(xer, "Spatial")
class(xer_sp)

# nrow(zerodist(xer_sp)) # indicates 1 pair of identical coordinates
# (zerodist(xer_sp)) # this gives the row numbers of the pair 136 & 158
# View(xer) # to view rows 136, site_id NLA17_WI-10027, & 158, NLA17_WI-10127

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(xer_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = xer_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=259280, row.names=xer_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(xer_sp)
plot(ds1nb1, ds1coords, labels = xer_sp$site_id, add = TRUE)


dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(xer)
# xer_df <- st_drop_geometry(xer)
# names(xer_df)
summary(xer$dissolved_n2o)

moran.plot(log(xer$dissolved_n2o), listw = dsnb1.listw, labels = xer$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## NLA
nla <- dg_sf1 %>% filter(visit_no == 1 & sample_source == "DG")

nla_sp <- as(nla, "Spatial")
class(nla_sp)

nrow(zerodist(nla_sp)) # indicates 2 pairs of identical coordinates
(zerodist(nla_sp)) # this gives the row numbers of the pair (192 & 210:  NLA17_IN-10002 & NLA17_IN-10047) and the pair (1028 & 1054:  NLA17_WI-10027, & 158, NLA17_WI-10127)
# View(nla) 

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(nla_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = nla_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=259280, row.names=nla_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(nla_sp)
plot(ds1nb1, ds1coords, labels = nla_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(nla)
# nla_df <- st_drop_geometry(nla)
# names(nla_df)
summary(nla$dissolved_n2o)

moran.plot(log(nla$dissolved_n2o), listw = dsnb1.listw, labels = nla$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)
```

## Correlograms: ncf and pgmirness packages
```{r, correlogram}

# Much of code below is based on example comparing correlograms among packages ncf, pgmirness, and spdep described in this chapter
# https://link.springer.com/chapter/10.1007/978-3-030-01989-1_5

coords <- data.frame(longitude = dg_1$map_lon_dd, latitude = dg_1$map_lat_dd)

dg_sf1 <- st_as_sf(dg_1, coords = c("map_lon_dd", "map_lat_dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting 

st_crs(dg_sf1)
names(dg_sf1)
nap_visit1 <- dg_sf1 %>% filter(wsa9 == "NAP" & visit_no == 1)
class(nap_visit1)
st_crs(nap_visit1)

nap_sp_visit1 <- as(nap_visit1, "Spatial")
class(nap_sp_visit1)

# trying ncf package which uses resampling to specify number of null permutations under the null to assess significance levels.  See if significance persist after increas resamp from 100 to 1000, which is the default.
# The x-intercept in the results is the distance at which objects are no more similar than expected by chance alone across the region.
# Run on CPL as that is giving correlation greater than 1, which according to Fletcher and Fortin might be due to small number of pairs of points used in that first distance bin or to outliers.  Perhaps, cluster of high Delaware sites (n visit 1 = 5) causes the correlation to be greater than 1.
# Looks like 71 pairs of points being used.
# With a lag, or bin distance, of 50 km only go out 10 bins, 500 km, and do a Bonferroni adjustment of 0.05/10 = 0.005
names(dg_1)
dg_cplvisit1 <- dg_1 %>% filter(wsa9 == "CPL" & visit_no == 1)
# N.B. default is resamp = 1000 so that can take 10 minutes for n =1090 sites
class(dg_cplvisit1)

correlo_n2o_ncf <- ncf::correlog(x = dg_cplvisit1$map_lon_dd, y = dg_cplvisit1$map_lat_dd, z = dg_cplvisit1$log_n2o, increment = 50, resamp = 1000, latlon = TRUE)
names(correlo_n2o_ncf)
plot(correlo_n2o_ncf) # works when pgmiress commented out
rm(dg_napvisit1, correlo_n2o_ncf)

# B/c returns a list of list have to access with [[]]
print(correlo_n2o_ncf[["n"]])
print(correlo_n2o_ncf[["mean.of.class"]])
print(correlo_n2o_ncf[["correlation"]])
head(correlo_n2o_ncf[["mean.of.class"]])
plot(correlo_n2o_ncf[["mean.of.class"]], correlo_n2o_ncf[["correlation"]])

class(correlo_n2o_ncf)
ncf::plot.correlog(correlo_n2o_ncf)

# CPL outlier check by working through all 10 pairwise removal of cluster of 5 high Delaware sites
out_cplvisit1 <- dg_1 %>% filter(wsa9 == "CPL" & visit_no == 1 & (site_id != "NLA17_DE-10003" & site_id != "NLA17_DE-10004"))

out_cplcorrelo_n2o <- ncf::correlog(x = out_cplvisit1$map_lon_dd, y = out_cplvisit1$map_lat_dd, z = out_cplvisit1$log_n2o, increment = 50, resamp = 1000, latlon = TRUE)

plot(out_cplcorrelo_n2o)
rm(out_cplvisit1, out_cplcorrelo_n2o)

# trying pgirmess package uses library spdep including moran.test and geary.test functions.  Distances are euclidean and in the same units as the spatial coordinates.  As run below, using geographical coordinates in decimal degrees so are distance classes retuned in decimal degrees?
# what if run on a spatial points data frame?
# Uses normality assumption, which is faster, to assess significance
coords_nap <- cbind(dg_napvisit1$map_lon_dd, dg_napvisit1$map_lat_dd)
correl_napn2o_pg <- pgirmess::correlog(coords_nap, dg_napvisit1$log_n2o, method = "Moran", nbclass = NULL, alternative = "two.sided")

head(round(correl_napn2o_pg, 2))
tail(round(correl_napn2o_pg, 2))
plot(correl_napn2o_pg)

# apply to SpatialPointsDataFrame that has projected coordinates and believe returning distance classes in meters
coords_sp_nap <- coordinates(nap_sp_visit1)
correl_spnapn2o_pg <- pgirmess::correlog(coords_sp_nap, nap_sp_visit1@data$log_n2o, method = "Moran", nbclass = 30, alternative = "two.sided")

head(round(correl_spnapn2o_pg, 2), 30)
tail(round(correl_spnapn2o_pg ,2))
plot(correl_spnapn2o_pg)
```

## Correlograms by Ecoregions
Doug Anderson wrote functions to deal with the list of list output from the correlog function in the ncf package.  He also wrote functions so that the correlogram of dissolved NO2 gas could be plotted by ecoregion using base plot, cowplot, or ggplot2 code.
```{r, correlogram_ecoregions}
# Original code from Doug Anderson at Neptune from file:  Neptune_correlogram_TDS05_Anderson.Rmd

# set the theme of the ggplot
theme_set(theme_bw()) # the theme I prefer is theme_bw()

## Can define a new function to plot
plot_correlog <- function(ncf_correlog, 
                          # names of list components
                          n_col = "n", 
                          mean_col = "mean.of.class",
                          cor_col = "correlation",
                          xint_col = "x.intercept",
                          pval_col = "p",
                          name_col = NULL, #can change to column that has names of interest
                          alpha = 0.05, # two sided significance level
                          # plot labels and adjustments
                          plot_title = "Correlogram", #can change to NULL
                          plot_subtitle = waiver(),
                          y_label = "Correlation",
                          x_label = "Distance (mean-of-class)",
                          pt_size = I(2), pt_color = "black",
                          ln_size = I(0.5), ln_color = "black", 
                          ln_type = "solid",
                          title_size = 14, subtitle_size = 14, 
                          axis_title_size = 14, axis_text_size = 14, 
                          title_color = "black", 
                          subtitle_color = "black",
                          axis_title_color = "black", 
                          axis_text_color = "black",
                          title_bold = TRUE, axis_bold = FALSE,
                          xaxis_color = "gray", xaxis_type = "solid",
                          theme_style = theme_bw()){
  # ncf_correlog is a list object exported from ncf::correlog() but can also be a dataframe with named columns
  
  # prepare a data set for plotting based on the list components or data frame columns
  dat <- data.frame(
    n = ncf_correlog[[n_col]],
    mean = ncf_correlog[[mean_col]],
    cor = ncf_correlog[[cor_col]],
    # xint = ncf_correlog[[xint_col]],
    pval = ncf_correlog[[pval_col]]
  )
  # create a variable to help plot the hollow and solid points
  # If a permutation test was performed, values significant at a nominal (two-sided) 5%-level 
  # will be represented by filled circles and non-significant values by open circles.
  dat$sig <- ifelse(dat$pval * 2 < alpha, TRUE, FALSE)
  
  ## Start the plot
  g <- ggplot(dat) +
    theme_style +
    geom_hline(yintercept = 0, color = xaxis_color, linetype = xaxis_type) +
    # geom_point(aes(x=mean, y=cor, shape=sig), size=pt_size, color=pt_color) +
    # geom_line(aes(x=mean, y=cor, group=1), size=ln_size, color=ln_color, linetype=ln_type) +
    lemon::geom_pointline(aes(x=mean, y=cor, shape=sig, group=1),
                          size = pt_size, color = pt_color, 
                          linetype = ln_type, linesize = ln_size, 
                          linecolor = ln_color) +
    scale_shape_manual(values=c("TRUE"=19, "FALSE"=1),
                       labels=c("TRUE"="Sig.", "FALSE"="Not Sig."),
                       guide=FALSE) +
    labs(x=x_label, y=y_label) 
  
  ## add a title
  if(!is.null(name_col)){#include a title if column for name is provided or list object has a list item for name
    if(!is.null(plot_title)){ #if plot_title is a string, separate the plot_title with the other name by a ':'
      nm <- unique(as.character(ncf_correlog[[name_col]]))
      g <- g + 
        ggtitle(label = paste(plot_title, ": ", nm, sep=""), subtitle = plot_subtitle)
    } else{ #if plot_title is null, only include the name
      nm <- unique(as.character(ncf_correlog[[name_col]]))
      g <- g + 
        ggtitle(label = nm, subtitle = plot_subtitle)
    }
  } else{ # if there is no name column, only include the plot_title of interest (can be NULL)
    g <- g + 
      ggtitle(label = plot_title, subtitle = plot_subtitle) 
  }
  
  ## modify theme
  g <- g + 
    theme(plot.title = element_text(size=title_size, 
                                    hjust=0.5, #change to a value between 0 (left) and 1 (right)
                                    face=ifelse(title_bold == TRUE, "bold", "plain"), 
                                    color=title_color),
          plot.subtitle = element_text(size=subtitle_size, 
                                       hjust=0.5, 
                                       color=subtitle_color),
          axis.title = element_text(size=axis_title_size, 
                                    face=ifelse(axis_bold == TRUE, "bold", "plain"), 
                                    color=axis_title_color),
          axis.text = element_text(size=axis_text_size, #?theme
                                   color=axis_text_color), #?element_text
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank())
  return(g)
}

dg_1 <- select(dg,site.id:map.lon.dd, dissolved.n2o, WSA9, WSA9_NAME, ONOFFNET, nitrate.n.result,chla.result.vol, MAX.BF, temp.surf, temp.bottom, o2.surf, o2.bottom, lake.orgn, state, size_cat)
names(dg_1)
dg_1 <- clean_names(dg_1)
names(dg_1)
dg_1 <- dg_1 %>% mutate(log_n2o = round(log(dissolved_n2o),3))
## Subset dg_1 by visit_no == 1
dg_visit1 <- dg_1 %>% dplyr::filter(visit_no == 1)

## Perform the same test for each wsa9 using Z = "log_n2o"
## Start by defining a function
ncf_correlog <- function(dat, # data to send to ncf::correlog
                         z_col, # name of the column in the dataset for water quality parameter
                         i = 50, # increment to be used in ncf::correlog
                         N = 1000, # number of resamples in ncf::correlog
                         x_col = "map_lon_dd", # name of the column in the dataset for longitude
                         y_col = "map_lat_dd", # name of the column in the dataset for latitude
                         lat_lon = TRUE, # if the x and y coordinates for ncf::correlog are lat and lon
                         rem_missing = FALSE, # argument of ncf::correlog
                         run_quietly = FALSE){ # argument of ncf::correlog
  library(ncf)
  
  X = dat[[x_col]] #grabs the x_col from data.frame
  Y = dat[[y_col]] #grabs the y_col from data.frame
  Z = dat[[z_col]] #grabs the z_col from data.frame
  
  ## Use ncf::correlog
  crlg <- ncf::correlog(x = X, y = Y, z = Z, 
                        increment = i, resamp = N, latlon = lat_lon, 
                        na.rm = rem_missing, quiet = run_quietly)
  return(crlg)
} 

## Split the dataframe by each wsa9: turns the data frame into a list 
##   where each list item is a data frame filtered to that wsa9
## lapply applies the function ncf_correlog on each list object (a data frame)
## the final product is a list of correlog objects
## this is similar to looping
## setting seed so get same result from permutations ncf::correlog function
set.seed(2035)
log_n2o_correlog_list <- dg_visit1 %>%
  split(.$wsa9) %>% # '.' means use the data frame that preceded this line
  lapply(function(x) ncf_correlog(dat = x, z_col = "log_n2o")) 
#ncf_correlog is the function name, 
#dat is the paramater that takes a data.frame,
#z_col is the parameter that takes a string name for a column of a water quality paramater

## look at the structure: list of 9 items where each item is a 
##   list containing 6 items: n, mean, correlation, x.int, p, call
str(log_n2o_correlog_list)

## Function to remove the list item 'call' which is of a different length 
##   than the other items (n, mean, correlation, x.int, and p)
## This function will also convert each list item to a dataframe
crlg_to_dat <- function(ncf_correlog, # ncf_correlog is a list object that was output from ncf::correlog
                        n_col = "n", 
                        mean_col = "mean.of.class",
                        cor_col = "correlation",
                        xint_col = "x.intercept",
                        pval_col = "p"){ 
  dat <- data.frame(
    n = ncf_correlog[[n_col]],
    mean = ncf_correlog[[mean_col]],
    cor = ncf_correlog[[cor_col]],
    xint = ncf_correlog[[xint_col]],
    pval = ncf_correlog[[pval_col]]
  )
  return(dat)
}

## log_n20_correlog_list is already a list so there is no need to split
log_n2o_correlog_dats <- lapply(log_n2o_correlog_list, 
                                function(x) crlg_to_dat(ncf_correlog = x))
str(log_n2o_correlog_dats) # each item in the list is now a dataframe

## combine into one dataframe to grab the wsa9 (notice the name no longer has an s at the end)

log_n2o_correlog_dat <- log_n2o_correlog_dats %>%
  dplyr::bind_rows(., .id = "wsa9")

str(log_n2o_correlog_dat)
head(log_n2o_correlog_dat)
## Make individual plots, the following object is a list containing a ggplot for each
log_n2o_correlog_plots <- log_n2o_correlog_dat %>%
  split(.$wsa9) %>% # splits the data frame by wsa9, which creates a list with 9 data frames
  lapply(function(x) plot_correlog(ncf_correlog = x, # use the data.frame for each wsa9 to make a plot
                                   plot_title = NULL,
                                   n_col = "n", 
                                   mean_col = "mean",
                                   cor_col = "cor",
                                   xint_col = "xint",
                                   pval_col = "pval",
                                   name_col = "wsa9",
                                   title_size = 14, 
                                   subtitle_size = 14, 
                                   axis_title_size = 14, 
                                   axis_text_size = 14))
## if hard to see writing run again but increase "title_size", "subtitle_size", "axis_title_size", "axis_text_size" as needed 

## Look at each piece individually or scroll through
length(log_n2o_correlog_plots) # shows 9 items
# log_n20_correlog_plots
log_n2o_correlog_plots$CPL #or log_n20_correlog_plots[["CPL"]] or log_n2o_correlog_plots[[1]]
# log_n2o_correlog_plots$NAP
# log_n2o_correlog_plots$NPL
# log_n2o_correlog_plots$SAP
# log_n2o_correlog_plots$SPL
# log_n2o_correlog_plots$TPL
# log_n2o_correlog_plots$UMW
# log_n2o_correlog_plots$WMT
# log_n2o_correlog_plots$XER

## cowplot package (or other) can be used to group them into a matrix plot
log_n2o_correlog_plotgrid <- 
  cowplot::plot_grid(plotlist=log_n2o_correlog_plots, ncol=3)
print(log_n2o_correlog_plotgrid) # click 'Zoom' in plots quadrant, takes a few seconds to render
## can save the plot using 
# cowplot::ggsave(filename = "FILENAME.png", #saves a png version of the figure to the working folder
#                 plot = log_n20_correlog_plotgrid)
## can change .png to other forms
## can play with scale, width, and height to adjust the output of the figure saved to the png file

## alternatively, can make a facet plot since log_n20_correlog_dat is a dataframe in the correct format
names(log_n2o_correlog_dat) #"n"    "mean" "cor"  "xint" "pval" "wsa9"

## create column to shape point, sig == TRUE means two-sided test < 0.05
log_n2o_correlog_dat$sig <- ifelse(log_n2o_correlog_dat$pval * 2 < 0.05,
                                   TRUE, FALSE) 
head(log_n2o_correlog_dat)
## can change wsa9 to a factor to arrange what order the plots are shown, otherwise default arranges them alphabetically
# log_n20_correlog_dat$wsa9 <- factor(log_n20_correlog_dat, 
#                                     levels = c("CPL", "NAP", "NPL", "SAP", "SPL", "TPL", "UMW", "WMT", "XER"))

## make facet plot
log_n2o_correlog_facetplot <- ggplot(log_n2o_correlog_dat) +
  geom_hline(yintercept = 0, color = "gray", linetype = "solid") +
  # geom_point(aes(x=mean, y=cor, shape=sig), size=I(2), color="black") +
  # geom_line(aes(x=mean, y=cor, group=1), size=I(0.5), color="black", linetype="solid") +
  lemon::geom_pointline(aes(x=mean, y=cor, shape=sig, group=1), 
                        size=I(2), color = "black", 
                        linetype = "solid", linesize = I(0.5), 
                        linecolor = "black") +
  scale_shape_manual(values=c("TRUE"=19, "FALSE"=1), 
                     labels=c("TRUE"="Sig.", "FALSE"="Not Sig."),
                     guide=FALSE) +
  facet_wrap(~wsa9, ncol=3, scales="free") +
  labs(x="Distance (mean-of-class)", y="Correlation") +
  theme_bw() +
  theme(plot.title = element_text(size=14, hjust=0.5, 
                                  face="bold", color="black"),
        plot.subtitle = element_text(size=14, hjust=0.5, color="black"),
        axis.title = element_text(size=14, face="plain", color="black"),
        axis.text = element_text(size=14, color="black"),
        strip.text = element_text(size=14, color="black", face="bold"),
        strip.background = element_rect(fill="gray", color="black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
print(log_n2o_correlog_facetplot)
## can save the plot using 
# cowplot::ggsave(filename = "FILENAME2.png", #saves a png version of the figure to the working folder
#                 plot = log_n20_correlog_facetplot) 
## can change .png to other forms
## can play with scale, width, and height to adjust the output of the figure saved to the png file



```

```

## Semivariograms
Variograms display the variability among pairs of points at various separation distances.  I was unable to fit a model to the dissolved gas concentration variograms using the default fitting parameters in gstat.  The variograms suggest a lack of spatial structure, but I suspect the model parameterization can be improved.

```{r, warning=FALSE, message=FALSE}
# Variogram function requires sp object
dg.sp <- as(dg.sf, Class = "Spatial")

# CO2 variogram
co2.v <- variogram(dissolved.co2~1, dg.sp)
co2.v.fit <- fit.variogram(co2.v, vgm(c("Exp", "Mat", "Sph"))) # allow to choose best model.  Not sure which model warnings are associated with.
# co2.v.fit # chose sperical
co2.v.fit <- fit.variogram(co2.v, vgm("Sph")) # refit spherical, several warnings (?)

# CH4 variogram
ch4.v <- variogram(dissolved.ch4~1, dg.sp)
ch4.v.fit <- fit.variogram(ch4.v, vgm(c("Exp", "Mat", "Sph"))) # allow to choose best model.  Not sure which model warnings are associated with.
# ch4.v.fit # chose exp
ch4.v.fit <- fit.variogram(ch4.v, vgm("Exp")) # refit exponential, no convergence

# N2O variogram
n2o.v <- variogram(dissolved.n2o~1, dg.sp)
n2o.v.fit <- fit.variogram(n2o.v, vgm(c("Exp", "Mat", "Sph"))) # allow to choose best model.  Not sure which model warnings are associated with.
# n2o.v.fit # chose exp
n2o.v.fit <- fit.variogram(n2o.v, vgm("Exp")) # refit exponential, no convergence


# Plot variograms and models (if fit)
plot(co2.v, model = co2.v.fit, main = "CO2 semivariogram")
plot(ch4.v, main = "CH4 semivariogram")
plot(n2o.v, main = "N2O semivariogram")

```

# Exploratory analysis of N2O data
The mean N2O saturation ratio for the country is `r pop.eco.sat %>% filter(type == "National", subpopulation == "National", indicator == "N2O_SAT_RATIO") %>% select(estimate) %>% pull() %>% round(2)` (95% CI = `r pop.eco.sat %>% filter(type == "National", subpopulation == "National", indicator == "N2O_SAT_RATIO") %>% select(lcb95pct) %>% pull() %>% round(2)` - `r pop.eco.sat %>% filter(type == "National", subpopulation == "National", indicator == "N2O_SAT_RATIO") %>% select(ucb95pct) %>% pull() %>% round(2)`), suggesting that US waterbodies are a new N2O sink during the NLA index period.  This finding is consistent with a recent report that 67% of 101 agricultural ponds in Canada were undersaturated in N2O during the summer (Webb et al. 2019, PNAS).

There are several sources of N2O in surface waters.  The overlying atmosphere contains trace quantities of N2O (~300 ppb) that dissolve into surface waters as a function of barometric pressure and water temperature.  N2O is also produced and consumed in aquatic ecosystems via denitrification.  Denitrification is the reduction of oxidized forms of N (i.e. NO3) to more reduced forms (i.e. N2).  It is a form of anaerobic respiration where oxidized forms of N serve as the electron acceptor in the absence of more energetically favorable alternatives, such as oxygen.  N2O concentrations/fluxes are therefore somewhat dependent upon the availability of oxidized N and low dissolved oxygen.  N2O can also be produced via nitrification.  Nitrification is the aerobic oxidation of NH4 to more oxidized forms.  N2O can be produced as a byproduct during the process and rates are somewhat dependent upon the availability of ammonium.  See Beaulieu et al. 2011, 2014, and 2015 for more information. 

The effect of denitrification and nitrification on dissolved N2O concentrations near the air-water interface is somewhat mediated by hydrology.  Denitrification is an anaerobic process that occurs predominantly in the sediment or anoxic hypolimnion.  Therefore, N2O must advect or diffuse from the sediment/hyoplimion to the water surface before it can affect dissolved N2O concentration near the air/water interface (where NLA samples were collected).  Previous invesitgations have interpretted correlations between N2O and lake size and degree of thermal stratification as indicative of hydrologic control (DelSontro et al. 2019, Webb et al. 2019).

DelSontrol et al. (2019) reported that N2O emission rates were positively related to chl a.  The authors (inlcuding me, I'm one of the 'authors'!) speculate that chla is a surrogate for labile carbon.  Denitrification requires carbon, so perhaps high rates of denitrification-N2O production occur in the presence of abundant carbon availability.

We do not yet have depth profiles of DO or temperature.  When these data become available, we can include bottom water DO and strength of thermal stratification in the model.  For now, we can explore correlations with the following variables.  

* MeanDUsed - mean depth  
* ph.result - pH  
* nitrate.n.result - NO3-N (mg/L)  
* ntl.lab.result - total nitrogen (mg/L)  
* chla.result.vol - chlorophyll a (ug/L)  
* ptl.lab.result - total phosphorus (mg/L)  
* surftemp - surface water temperature (C)  

A correlation matrix of dissolved N2O concentration and potential controlling variables doesn't show any striking relationships, though the strongest relationship is with nitrate.  

```{r}
library(corrr)
dg %>%
  select(dissolved.n2o, MeanDUsed, ph.result, nitrate.n.result, ntl.lab.result, chla.result.vol, ptl.lab.result, surftemp) %>%
  correlate()
```

Categorization and regression analysis (CART), which can accomodate non-linear and interactive relationships, also identified nitrate as the most important predictor variable.  The CART analysis did not identify splits associated with ecoregion.

```{r}
library(tree)
model <- tree(dissolved.n2o ~ MeanDUsed + nitrate.n.result + ntl.lab.result + chla.result.vol + ptl.lab.result + surftemp + WSA9, data = dg)

plot(model)
text(model)

```

We may also want to include design variables in the analysis.  The specifics of the NLA17 design have not been disseminated, but are likely very similar to the NLA12 design.  Per the NLA12 Design Documentation (https://www.epa.gov/sites/production/files/2014-03/documents/nla2012_design_documentation_20110320.pdf):

> Stratification  
The survey design was stratified by state and by NLA12_CLS. NLA12_CLS has three classes: (1) NLA07RVT – defined as all NLA 2007 lakes that were target and sampled, (2) NLA12NEW – remaining lakes in NHD-Plus that are included in the sample frame, and (3) Exclude – lakes in NHD-Plus that are excluded from the sample frame (see Sample Frame section above). Each state design has two strata, ST_ NLA07RVT and ST_ NLA12NEW (where ST is replaced by two letter state abbreviation. The total number of strata is 96 (two for each state).

> Unequal Probability Categories  
The 48 state strata for lakes from the NLA 2007 that would be visited again in 2012 was an equal probability design within each stratum. The 48 state strata NLA12NEW was an unequal probability design within each state stratum. The unequal probability categories were defined based on lake area: 1 to 4 ha, 4 to 10 ha, 10 to 20 ha, 20 to 50 ha and greater than 50 ha.

As you can see, the design is actually pretty complicated.  The file currently contains the following design elements:  

* state - two digit state abbreviation.  See line 62 above.
* AREASQKM - waterbody area (km2)

Corvallis has not yet shared the other design elements (i.e. NLA17_CLS) and sample weights.  Presumably this file will be delivered with the code to execute the population estimates via spSurvey.  Steve Paulsen will speak to Tom Kincaid about this during the week of Dec. 16.