---
title: "Analysis of NLA17 Dissolved Gas Indicator"
authors: "J. Beaulieu, R. Martin, and M. McManus"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    fig_caption: yes
    depth: 2
    number_sections: true
    code_folding:  hide
editor_options: 
  chunk_output_type: console
---

```{r results='hide', message=FALSE, warning=FALSE}
# load libraries
library(sf) # spatial data
library(gstat) # lagged scatterplot, variogram
library(tidyverse) # dplyr, ggplot
library(janitor) # clean names
library(spdep) # k-NN and Moran plot
library(ncf) # ncf::correlogram
library(lattice) # xyplot


# Identify local path for each user
localPath <- Sys.getenv("USERPROFILE")

# Define helper functions
# standardized formatting for column names
toEPA <- function(X1){
  names(X1) = tolower(names(X1))
  names(X1) = gsub(pattern = c("\\(| |#|)|/|-|\\+|:|_"), replacement = ".", x = names(X1))
  X1
}
```


# Background
During the 2017 National Lakes Assesment, duplicate dissolved gas samples were collected at a depth of ~0.1m at the index site at each waterbody.  Gas samples were analyzed for CO~2~, CH~4~, and N~2~O concentration via gas chromatography and $\delta^{13}CO_{2}$ and $\delta^{13}CH_{4}$ via cavity ring-down spectroscopy.  The following analysis pertains to the concentration data.


## Getting data and filtering
The dissolved gas data were currated the 'NLA' dissolved gas project in RStudio.  The code can be found at a private github repository (https://github.com/USEPA/NLA).  After aggregating across duplicate samples, the data were written to nla17gasDataAggregated_2020-02-24.txt.  A copy of this data file is stored in documents library associated with the 'ORD NLA17 Dissolved Gas' Private Group on SharePoint (https://usepa.sharepoint.com/sites/ORD_NLA17_Dissolved_Gas).  This file was futher manipulated in "C://Users//JBEAULIE//OneDrive-Environmental Protection Agency (EPA)//gitRepository//DissolvedGasNla//scripts//dataMunge.Rmd" and written out as an .RData object, which is imported below.


```{r}
# Had used dg.2021-01-14 now try dg.2021-02-01.RData to see if results change
 load(paste0(localPath,
            "/Environmental Protection Agency (EPA)/",
            "ORD NLA17 Dissolved Gas - Documents/",
            "inputData/dg.2021-02-01.RData"))

```



The data file contains `r dg %>% distinct(site.id, visit.no) %>% summarize(n = n()) %>% pull()` unique sampling trips defined by unique combinations of 'site.id' and 'visit.no'.  There were `r dg %>% distinct(site.id) %>% summarize(n = n()) %>% pull()` waterbodies sampled, `r dg %>% filter(visit.no == 2) %>% summarize(n = n()) %>% pull()` of which were sampled twice. The primary response variables are the concentrations of CO~2~, CH~4~, and N~2~O dissolved in the surface water of each waterbody.  Concentration is expressed in both mass based units (umol/L, nmol/L: dissolved.co2, dissolved.ch4, dissolved.n2o) and as a saturation ratio (co2.sat.ratio, ch4.sat.ratio, n2o.sat.ratio).  Saturation ratio is defined as the ratio of the measured concentration to that expected if the waterbody were in equilibrium with the atmosphere.  A value of 1 indicates equilibrium, values < 1 indicate undersaturation and values > 1 indicate supersaturation.  Undersaturated waterbodies function as a sink for the atmospheric gas whereas supersaturated waterbodies function as a source.


```{r}
# These are the main response variables.
dg %>% 
  select(dissolved.co2.umol, dissolved.ch4.umol, dissolved.n2o.nmol, co2.sat.ratio, ch4.sat.ratio, n2o.sat.ratio) %>%
  {summary(.)}

names(dg)

dg %>% 
  ggplot(aes(as.factor(x = ag.eco9), y = log(dissolved.n2o.nmol))) + geom_boxplot()
# shows a boxplot for NA category

dg %>% 
  ggplot(aes(as.factor(x = ag.eco9), y = (n2o.sat.ratio))) + geom_boxplot()
# shows a boxplot for NA category
```


#  Exploratory spatial analysis
## Population estimates by ecoregion
### Dissolved gas concentration
The survey design allows for population estimates of central tendency and variance by ecoregion (and other subpopulations), which can provide insight into spatial patterning.  There is broad overlap in mean +/- 95% CI estimates for dissolved CH~4~ and N~2~O concentration across ecoregions.  The Northern Plains, Temperate Plains, and Western Mountains have low dissolved CO~2~ concentration.  

```{r, fig.cap= "Fig. caption: Mean +/- 95% CI for the dissolved gas concentration indicator"}
# Read population estimates calculated with local neighborhood variance estimate.  Code provided by Tom Kincaid 
# (12/12/2019), then modified to accomdate the gas emission rate and flux variables.  See CDF_Estimates_Jb.Rmd.
pop <- read.csv(file = paste0(localPath, 
                              "/Environmental Protection Agency (EPA)/",
                              "ORD NLA17 Dissolved Gas - Documents/",
                              "inputData/populationEstimates/",
                              "NLA_2017_Percentile_Estimates_Local_Mean_JB20201202.csv"),
                as.is = TRUE) %>%
  toEPA()  # enforce formatting convention

# Convert units for dissolved gas concentration indicator
pop <- pop %>%
  mutate(estimate = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            estimate * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            estimate * 1000000000, # mol/L -> nmol/L for n2o
                            estimate)), # all others
         lcb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            lcb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            lcb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            lcb95pct)), # all others
         ucb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            ucb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            ucb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            ucb95pct))) # all others


# extract population estimates for ecoregion and nation
pop.eco <- pop %>% 
  filter(type %in% c("AG_ECO9_NM", "National"), # extract estimates for ecoregion and nation
         statistic == "Mean") # extract mean estimate

# extract dissolved gas indicator, order by dissolved CH4
pop.eco.diss <- pop.eco %>%
  filter(grepl("dissolved", indicator, ignore.case = TRUE)) %>%
  mutate(subpopulation = factor(subpopulation, 
                             levels = filter(pop.eco, indicator == "DISSOLVED_CH4", subpopulation != "National") %>%
                               arrange(estimate) %>%
                               select(subpopulation) %>%
                               pull() %>%
                               c("National", .)))
  
# look at dissolved concentration indicator
ggplot(pop.eco.diss, aes(estimate, subpopulation)) +
  geom_point() +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct)) +
  facet_wrap(~indicator, scales = "free_x") +
  theme(axis.title = element_blank())
```

### Dissolved gas saturation ratios and source/sink status
Dissolved gas saturation ratios are calculated as the ratio of the observed to equilibrium concentration.  The equilibrium concentration (sometimes called the saturation concentration) is the concentration expected if the waterbody were in equilibrium with the atmosphere.  It is calculated from the partial pressure of the gas in the atmosphere, water temperature, and the gas specific solubility.  Saturation ratios >1 indicate the water body is supersaturated and is a source of the gas to the atmosphere.  Saturation ratios <1 indicate that the waterbody is undersaturated and is consuming the gas from the atmosphere.  The saturation ratio can therefore be used to categorize each waterbody as a 'sink' or a 'source'.

``` {r}
# read in source/sink population data
# Read extent estimates generated with CDF_Estimates_Jb.Rmd.  File provided by Tom Kincaid (12/12/2019), then modified to accomodate the gas emission rate, flux variables, and cat.analysis for N2O source/sink.  
n2o.extent <- read.csv(file = paste0(localPath, 
                                     "/Environmental Protection Agency (EPA)/",
                                     "ORD NLA17 Dissolved Gas - Documents/",
                                     "inputData/populationEstimates/",
                                     "NLA_2017_Extent_Estimates20201203.csv"),
                       as.is = TRUE) %>%
  toEPA() %>% # enforce formatting convention
  filter(type %in% c("AG_ECO9_NM", "National"), # extract estimates for ecoregion and nation
         category == "sink") %>% # extract extent estimate for sink
  mutate(subpopulation = factor(subpopulation, # arrange by extent estimate for sink
                                levels = filter(., subpopulation != "National") %>%
                                  arrange(estimate.p) %>%
                                  select(subpopulation) %>%
                                  pull() %>%
                                  c("National", .)))
```

The binary 'source' or 'sink' values can be analyzed at the population level using the cat.analysis function in the spsurvey package. The function provides an 'extent' estimate, which is the proportion of waterbodies in each region that are functioning as a source or sink. Over half of the waterbodies are functioning as N2O sinks in all ecoregions.  At the national scale, `r n2o.extent %>% filter(type == "National") %>% select(estimate.p) %>% pull() %>% round(., 1)`% (95% CI: `r n2o.extent %>% filter(type == "National") %>% select(lcb95pct.p) %>% pull() %>% round(., 1)` - `r n2o.extent %>% filter(type == "National") %>% select(ucb95pct.p) %>% pull() %>% round(., 1)`) of lakes and reservoirs were net N~2~O sinks during the index period, suggesting that US lakes and reservoirs are a net N~2~O sink.  However, the 95% confidence intervals of the mean N~2~O saturation ratio include 1 for all ecoregions except the Northern plains which are undersaturated.  At the national scale, the mean N~2~O saturation ratio indicates supersaturation (`r pop.eco %>% filter(type == "National", statistic == "Mean", indicator == "N2O_SAT_RATIO") %>% select(estimate) %>% pull() %>% round(., 2)`% (95% CI: `r pop.eco %>% filter(type == "National", statistic == "Mean", indicator == "N2O_SAT_RATIO") %>% select(lcb95pct) %>% pull() %>% round(., 2)` - `r pop.eco %>% filter(type == "National", statistic == "Mean", indicator == "N2O_SAT_RATIO") %>% select(ucb95pct) %>% pull() %>% round(., 2)`)), suggesting that US lakes and reservoirs function as a net N~2~O sink.  These findings indicate that high levels of N~2~O saturation in a few waterbodies offset undersaturation in most waterbodies, yielding a mean saturation ratio > 1.   

```{r message=FALSE}

## Bubble plot of observed N2O saturation index----------------
# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg$map.lon.dd, latitude = dg$map.lat.dd)

dg.sf <- st_as_sf(dg, coords = c("map.lon.dd", "map.lat.dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting



# read in ecoregion polygons
ecoR <- st_read(dsn = paste0(localPath, 
                             "/Environmental Protection Agency (EPA)/",
                             "ORD NLA17 Dissolved Gas - Documents/inputData"),
                layer = "aggr_ecoregions_simple")

# Check CRS
#st_crs(ecoR) # 3857
ecoR <- st_transform(ecoR, 5070) # convert to CONUS Albers
#st_crs(ecoR) # 5070

ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = n2o.sat.ratio, color = n2o.src.snk),
          show.legend = "point") +
  ggtitle("N2O saturation ratio") +
  scale_color_manual(values = c("white", "black"), name = "source/sink") +
  scale_size_binned(name = "N2O saturation ratio",
             range = c(1, 8), # custom size range
             breaks = c(0.1, 0.5, 1, 2))  # custom breaks



## horizontal bar chart of N2O sink extent---------------
ggplot(n2o.extent, aes(estimate.p, subpopulation)) +
  geom_bar(stat = "identity", aes(fill = subpopulation, color = subpopulation), alpha = 0.25) +
  geom_errorbarh(aes(xmax = ucb95pct.p, xmin = lcb95pct.p, color = subpopulation), height = 0, size = 1) +
  xlab("Percent of waterbodies functioning as N2O sinks") +
  theme(axis.title.y = element_blank())



## horizontal bar chart of N2O saturation ratio-------------
# extract saturation indicator, order by n2o extent (see above).  This enforces same order for both plots.
pop.eco.sat <- pop.eco %>%
  filter(grepl("sat", indicator, ignore.case = TRUE)) %>%
  mutate(subpopulation = factor(subpopulation, 
                             levels = filter(n2o.extent, subpopulation != "National") %>%
                                  arrange(estimate.p) %>%
                                  select(subpopulation) %>%
                                  pull() %>%
                               as.character() %>%
                                  c("National", .)))
  
# N2O saturation ratio; horizontal bar chart
ggplot(filter(pop.eco.sat, indicator == "N2O_SAT_RATIO"), aes(estimate, subpopulation)) +
  geom_bar(stat = "identity", aes(fill = subpopulation, color = subpopulation), alpha = 0.25) +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct, color = subpopulation), height = 0, size = 1) +
  xlab("N2O saturation ratio") +
  theme(axis.title.y = element_blank()) +
  geom_vline(xintercept = 1)


```



### Emission rates and flux
The emission rate (E~gas~) is the rate at which a gas crosses the air water interface and is expressed on an areal basis (i.e. mass m^-2^ day^-1^).  It is calculated as a function of the dissolved gas concentration and gas transfer velocity (see dataMunge.Rmd).  The 95% confidence interval of the mean N~2~O emission rate is quite large in several ecoregions, encompassing 0 in all but the Northen Plains and Xeric ecoregions.  The mean N~2~O emission rate at the national scale is positive (`r  pop.eco %>% filter(indicator == "E_N2O_NMOL_D", subpopulation == "National", statistic == "Mean") %>% select(estimate) %>% pull() %>% round(., 1)/1000` umol N~2~O m^-2^ day^-1^), although the 95% confidence interval includes 0, similar to the N~2~O saturation ratio pattern.  

```{r, fig.cap= "Fig. caption: Mean +/- 95% CI for the emission rate (mass of GHG time-1 area-1)"}
# extract population estimates for ecoregion and nation
pop.eco.emission <- pop.eco %>% 
  filter(grepl("^E", indicator)) %>% # ^ means starts with.  Extract the emission rates 
  # order by N2O
   mutate(subpopulation = factor(subpopulation, 
                             levels = filter(., indicator == "E_N2O_NMOL_D", subpopulation != "National") %>%
                               arrange(estimate) %>%
                               select(subpopulation) %>%
                               pull() %>%
                               c("National", .)))


# look at dissolved concentration indicator
ggplot(filter(pop.eco.emission, indicator == "E_N2O_NMOL_D"), 
       aes(estimate/1000, subpopulation)) + # convert to umol
  geom_point(aes(color = subpopulation, fill = subpopulation), alpha = 0.25, size = 5) +
  geom_errorbarh(aes(xmax = ucb95pct/1000, xmin = lcb95pct/1000, color = subpopulation), height = 0, size = 1) + # convert to umol
  geom_vline(xintercept = 0) +
  xlab("N2O emission rate (umol N2O m-2 day-1") + # converted from nmol to umol (see above)
  theme(axis.title.y = element_blank())
  
```

The N~2~O flux at a waterbody is the total mass of N~2~O crossing the air-water interface per unit time (e.g. mass N~2~O day^-1^) and is calculated as the product of the emission rate (mass N~2~O m^-2^ day^-1^) and waterbody area (m^2^).  Negative values indicate N2O invasion into the waterbody and positive values indicate N~2~O efflux from the waterbody to the atmosphere.  An assessment of the role of lakes and reservoirs in the atmospheric N~2~O budget must be based on flux, rather than emission rates, because flux accounts for waterbody size.  For example, N~2~O emissions from several small waterbodies could be completely offset by N~2~O uptake by a single large waterbody with a small negative emission rate (e.g. N~2~O sink), yet the mean emission rate for these waterbodies would be > 0.   

The mean N~2~O flux per waterbody is close to zero for most ecoregions and the 95% confidence interval includes zero for all ecoregions.  The national scale mean N~2~O flux is slightly negative (`r  pop.eco %>% filter(indicator == "F_N2O_M_D", subpopulation == "National", statistic == "Mean") %>% select(estimate) %>% pull() %>% round(., 2)` mol N~2~O day^-1^), but the 95% CI includes 0.  

```{r, fig.cap= "Fig. caption: Mean +/- 95% CI of the GHG flux across the air-water interface (mass GHG / time)"}
# extract population estimates for ecoregion and nation
pop.eco.flux <- pop.eco %>% 
  filter(grepl("^F", indicator)) %>% # ^ means starts with.  Extract the flux rates 
  # order by N2O
   mutate(subpopulation = factor(subpopulation, 
                             levels = filter(., indicator == "F_N2O_M_D", subpopulation != "National") %>%
                               arrange(estimate) %>%
                               select(subpopulation) %>%
                               pull() %>%
                               c("National", .)))


# look at dissolved concentration indicator
ggplot(filter(pop.eco.flux, indicator == "F_N2O_M_D"),
       aes(estimate, subpopulation)) +
  geom_point(aes(color = subpopulation, fill = subpopulation), alpha = 0.25, size = 5) +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct, color = subpopulation), height = 0, size = 1) +
  geom_vline(xintercept = 0) +
  xlab("N2O flux (mol N2O day^-1 waterbody^-1") +
  theme(axis.title.y = element_blank())

  
```


### 13C paper
```{r}
# 13C; horizontal bar chart by ecoregion
pop.eco.13c <- filter(pop.eco, indicator == "DELTA_13_CH4_C")
ggplot(pop.eco.13c, aes(estimate, subpopulation)) +
  geom_bar(stat = "identity", aes(fill = subpopulation, color = subpopulation), alpha = 0.25) +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct, color = subpopulation), height = 0, size = 1) +
  theme(axis.title.y = element_blank()) 

# 13C; horizontal bar chart by origin
pop.origin.13c <- filter(pop, type == "LAKE_ORGN", statistic == "Mean", indicator == "DELTA_13_CH4_C")
ggplot(pop.origin.13c, aes(estimate, subpopulation)) +
  geom_bar(stat = "identity", aes(fill = subpopulation, color = subpopulation), alpha = 0.25) +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct, color = subpopulation), height = 0, size = 1) +
  theme(axis.title.y = element_blank()) 


# 13C; horizontal bar by size
pop.size.ch4 <- filter(pop, type == "AREA_CAT6", statistic == "Mean", indicator == "DISSOLVED_CH4")
ggplot(pop.size.ch4, aes(estimate, subpopulation)) +
  geom_bar(stat = "identity", aes(fill = subpopulation, color = subpopulation), alpha = 0.25) +
  geom_errorbarh(aes(xmax = ucb95pct, xmin = lcb95pct, color = subpopulation), height = 0, size = 1) +
  theme(axis.title.y = element_blank()) 



# 13CH4 Bubble plots

ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = delta.13.ch4), 
          show.legend = "point") + # improve legend
  ggtitle("13CH4") +
  scale_size(name = "13C-CH4",
             range = c(0.05, 3), # custom size range
             breaks = c(-80, -50, -25, 0)) # custom breaks

```


Similarly, we can look at population level estimates of GHG emission rates (mass of GHG time^-1^ area^-1^).




We can also look at the GHG flux across the air-water interface (mass GHG time^-1^)



## Simple random sample vs local neighborhood variance estimator
Population level estimates of variance can be calculated using a simple random sample or local neighborhood estimators.  The local neighborhood estimator will yield lower variance estimates if there is spatial structure in the data.  Below are plotted the 95% confidence intervals calculated using both methods.  In nearly all cases the local neighborhood estimator yields a more restricted interval.

```{r, message=FALSE}
# calculate 95% CI using local neighborhood estimator
pop.eco.diss <- pop.eco.diss %>%
  mutate(ci95.local = ucb95pct - lcb95pct)

# read in SRS estimator population estimates provided by Tom Kincaid (12/12/2019)
pop.srs <- read.csv(file = paste0(localPath, 
                              "/Environmental Protection Agency (EPA)/",
                              "ORD NLA17 Dissolved Gas - Documents/",
                              "inputData/populationEstimates/",
                              "NLA_2017_Percentile_Estimates_SRS_20191212.csv"),
                as.is = TRUE) %>%
  toEPA()  # enforce formatting convention

# Convert units for dissolved gas concentration indicator
pop.srs <- pop.srs %>%
  mutate(estimate = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            estimate * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            estimate * 1000000000, # mol/L -> nmol/L for n2o
                            estimate)), # all others
         lcb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            lcb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            lcb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            lcb95pct)), # all others
         ucb95pct = ifelse(grepl("dissolved.c", indicator, ignore.case = TRUE), # dissolved.co2 or dissolved.ch4
                            ucb95pct * 1000000, # mol/L -> umol/L for co2 and ch4
                           ifelse(grepl("dissolved.n", indicator, ignore.case = TRUE), # dissolved.n2o
                            ucb95pct * 1000000000, # mol/L -> nmol/L for n2o
                            ucb95pct))) # all others


# extract population estimates for ecoregion and nation
# dissolved gas indicator
pop.srs.eco.diss <- pop.srs %>% 
  filter(type %in% c("AG_ECO9_NM", "National"), # extract estimates for ecoregion and nation
         statistic == "Mean") %>% # extract mean estimate
  mutate(ci95.srs = ucb95pct - lcb95pct) %>%
  filter(grepl("dissolved", indicator, ignore.case = TRUE)) 

# merge local neighborhood and SRS variance estimates
pop.local.srs <- dplyr::full_join(pop.eco.diss,
                                  select(pop.srs.eco.diss, -nresp, -estimate, 
                                         -stderror, -lcb95pct, -ucb95pct)) %>%
  select(-nresp, -estimate, -stderror, -lcb95pct, -ucb95pct) %>%
  pivot_longer(cols = starts_with("ci95"))


# look at dissolved concentration indicator
ggplot(pop.local.srs, aes(value, subpopulation)) +
  geom_point(aes(color = name)) +
  facet_wrap(~indicator, scales = "free_x") +
  xlab("95% confidence interval of mean") +
  theme(axis.title.y = element_blank())
```




## Bubble plots
Bubble plots can be used to visualize patterns in geospatial data.  In the plots below, bubble size reflects the gas concentration and color reflects saturation status (i.e. source or sink).  The code immediately below converts the dataframe to a spatial object and reads in the ecoregion ploygons.  The first bubble plot below is of dissolved CO2 which seems to show a pattern of higher concentrations along the eastern seaboard.
```{r, message=FALSE}
# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg$map.lon.dd, latitude = dg$map.lat.dd)

dg.sf <- st_as_sf(dg, coords = c("map.lon.dd", "map.lat.dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting



# read in ecoregion polygons
ecoR <- st_read(dsn = paste0(localPath, 
                             "/Environmental Protection Agency (EPA)/",
                             "ORD NLA17 Dissolved Gas - Documents/inputData"),
                layer = "aggr_ecoregions_simple")

# Check CRS
st_crs(ecoR) # 3857
ecoR <- st_transform(ecoR, 5070) # convert to CONUS Albers
st_crs(ecoR) # 5070
```



```{r, message=FALSE}
# CO2 Bubble plots

ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = dissolved.co2.umol, color = co2.src.snk), 
          show.legend = "point") + # improve legend
  ggtitle("Dissolved CO2 (uM)") +
  scale_color_manual(values = c("white", "black"), name = "source/sink") +
  scale_size(name = "dissolved CO2 (uM)",
             range = c(0.1, 5), # custom size range
             breaks = c(10, 100, 300, 600)) # custom breaks
```

Spatial patterns in dissolved CH4 are not apparent, although all but two sites are supersaturated. 

```{r}
ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = dissolved.ch4.umol, color = ch4.src.snk), 
          show.legend = "point") +
  ggtitle("Dissolved CH4 (uM)") +
  scale_color_manual(values = c("white", "black"), name = "source/sink") +
  scale_size(name = "dissolved CH4 (uM)",
             range = c(0.1, 10), # custom size range
             breaks = c(0.1, 1, 10, 50, 100)) # custom breaks
```

The prevalance of undersaturated dissolved N2O concentrations is an important finding.  The IPCC assumes surface waters are an important source of N2O to the atmosphere.   Webb et al. recently published a paper in PNAS reporting that 70 out of 101 reservoirs sampled in Saskatchewan were N2O sinks.  This paper made quite a splash.  In our study, `r sum(dg$n2o.src.snk == "sink")` out of `r sum(!is.na(dg$dissolved.n2o.nmol))` sampled waterbodies were an N2O sink. It is somewhat interesting to note that the some of the highest concentrations were observed in Indiana/Ohio, where I conducted much of my dissertation research on aquatic N2O emissions.

```{r}
ggplot() +
  geom_sf(data = ecoR, color = NA, aes(fill = WSA9_NAME)) +
  geom_sf(data = dg.sf, aes(size = dissolved.n2o.nmol, color = n2o.src.snk),
          show.legend = "point") +
  ggtitle("Dissolved N2O (nM)") +
  scale_color_manual(values = c("white", "black"), name = "source/sink") +
  scale_size(name = "dissolved N2O (nM)",
             range = c(0.1, 10), # custom size range
             breaks = c(1, 10, 25, 50, 100)) # custom breaks
```



## Geopackage
Create a simple feature on entire dg data frame.  The geopackage will contain two simple features, the dissolved gas sampled points/lakes and the nine aggregated ecoregions.
```{r, geopackage, eval=FALSE, echo=FALSE,}

names(dg)
dg_1 <- clean_names(dg)
names(dg_1)
# dropped onoffnet variable as I don't think it occurs in this version of the data frame, dg.2021-01-14.RData
dg_1 <- filter( dg_1, sample_source == "DG")

dg_1 <- select(dg_1,site_id:date_col, map_lat_dd, map_lon_dd, dissolved_co2_umol, dissolved_ch4_umol, dissolved_n2o_nmol, co2_sat_ratio, ch4_sat_ratio, n2o_sat_ratio, ag_eco9, ag_eco9_nm, nitrate_n_result, chla_result, ntl_result, ph_result, ptl_result,max_bf, temp_surf, temp_bottom, o2_surf, o2_bottom, lake_orgn, pstl_code , area_cat6, silica_result, calcium_result, visit_no) %>% filter(visit_no == 1 & ag_eco9 != "AK")

names(dg_1)
str(dg_1)

dg_1 %>% 
  ggplot(aes(as.factor(x = ag_eco9), y = log(dissolved_n2o_nmol))) + geom_boxplot()
# now no longer show a boxplot for NA category

dg_1 %>% 
  ggplot(aes(as.factor(x = ag_eco9), y = (n2o_sat_ratio))) + geom_boxplot()
# now no longer show a boxplot for NA category

#filter in View returns 514 nitrate_n_result equal to zero
dg_1 <- dg_1 %>% mutate(log_n2o = round(log(dissolved_n2o_nmol),3)) %>%  
  mutate(log_ntl = round(log(ntl_result),3)) %>% 
  mutate(log_ptl = round(log(ptl_result),3)) %>% 
  mutate(log_chla = round(log(chla_result),1)) %>% 
  mutate(log_si = round(log(silica_result),2)) %>% 
  mutate(log_ca = round(log(calcium_result),2)) %>% 
  mutate(ph_result = round(ph_result,2))
# %>% 
#   mutate(nitrate_n_b = case_when(
#     nitrate_n_result <= 0.0001 ~ "low",
#     nitrate_n_result > 0.0001 ~ "high"))  
# 
# dg_1$nitrate_n_b <- factor(dg_1$nitrate_n_b, levels = c("low", "high"))
# summary(dg_1$nitrate_n_b)

# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg_1$map_lon_dd, latitude = dg_1$map_lat_dd)

dg_sf1 <- st_as_sf(dg_1, coords = c("map_lon_dd", "map_lat_dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting 
dim(dg_sf1) # 1184 observations


dg_sf1 <- filter(dg_sf1, sample_source == "DG") # now 1082 obs vs. 1184 obs vs. previously 1185 obs., why change in sample size
st_crs(dg_sf1)


# Bryan suggested EPSG 4326
# Bryan Chastain as GeoServices suggested reducing the number of fields, and I tried that but was still unable to open the geodatabase in ArcMap 
# Based on gis stackexchange I think the "." in variable names is causing the problem
# https://gis.stackexchange.com/questions/319611/arcgis-geopackage-arcmap-drawing-error?noredirect=1
# Even with change to _ still get error message about invalid coordinate system when st_transform(5070) used

# Check CRS
st_crs(ecoR)
names(ecoR)
# changed from 4326 to 5070
ecoR1 <- st_transform(ecoR, 5070) %>% 
  select(OBJECTID, WSA9, WSA9_NAME) # Grab variables of interest
st_crs(ecoR1)

# write out dg.sf and ecoR as two layers in geopackage, gpkg, geodatabase
# 74. Creating a geopackage geodatabase, then adding more layers
# https://github.com/r-spatial/sf/issues/392
# creating a _v1.gpkg having large sample size and should be in Albers
# st_write(dg_sf1, dsn = file.path(getwd(), "nladg_v1.gpkg"), layer = "dg_sf1", driver = "GPKG", quiet = FALSE, 
#          delete_layer = TRUE) # needed, else function gives error if object already exists
st_layers("nladg_v1.gpkg")

# N.B. b/c old layer with untransformed was already in geodatabase have to delete it and then append the new layer
st_write(dg_sf1, dsn = file.path(getwd(), "nladg_v1.gpkg"), layer = "dg_sf1", driver = "GPKG", delete_layer = TRUE, append = TRUE, quiet = FALSE)
st_layers("nladg_v1.gpkg")

# https://gis.stackexchange.com/questions/223240/writing-multiple-layers-to-geopackage-using-writeogr-in-r
st_write(ecoR1, dsn = file.path(getwd(), "nladg_v1.gpkg"), layer = "ecoR1", driver = "GPKG", append = TRUE, quiet = FALSE, delete_layer = TRUE) # needed, else function gives error if object already exists
st_layers("nladg_v1.gpkg")

names(dg_sf1)
summary(dg_sf1$dissolved_n2o_nmol) # matches Roy's stats
```

## Summarizing distances
Getting distances between sites overall and by ecoregion to help set distances for lagged scatterplots.  First, Worked out steps on a sample of NLA sites.  Could only get parts of Anna Springsteen's code to work.
```{r, eval=FALSE, echo=FALSE, distances}
names(dg.sf)
head(dg.sf$WSA9_NAME)
# distinct returns all unique geometry + attribute combinations.  convert to df if not interested in geometry
dg.sf %>% as.data.frame() %>% distinct(WSA9_NAME) 
# distinct.Spatial(dg.sf, WSA9_NAME) # this doesn't work either.
distinct(dg, WSA9_NAME)

# take a small sample of dg.sf to test getting distances
set.seed(1859)
# st_sample only returns a list of coordinates
nla_samp <- st_sample(dg.sf, 10, type = "random", exact = TRUE)
plot(nla_samp)
class(nla_samp)
head(nla_samp)

# sample_n keeps attributes and geometries
nla_samp1 <- sample_n(dg.sf, 10)
plot(nla_samp1, max.plot=1)
class(nla_samp1)
head(nla_samp1$site.id, 10)
distmat <- st_distance(nla_samp1,nla_samp1,by_element = FALSE)
class(distmat) # thought this would return matrix
max(distmat)
min(distmat)
summary(distmat) # think this returns summary of all pairwise distances on each obs, v1-v10
dim(distmat)

rdistmat <- distmat[1:10, ]
print(rdistmat)
rdistmat1 <- as.vector(rdistmat)
round(min(rdistmat1[rdistmat1!=0]))
round(quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[2])
round(median(rdistmat1[rdistmat1!=0]))
round(quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[4])
round(max(rdistmat1[rdistmat1!=0]))

names(ecoR)
class(ecoR)
# contrast ecoRname <- as.data.frame(select(ecoR,"WSA9_NAME"))
# geom is sticky with select but not pull
# ecoRname <- as.data.frame(pull(ecoR,"WSA9_NAME"))
ecoRname1 <- as.character(pull(ecoR,"WSA9_NAME")) #Springsteen code needs to be character to populate columns of matrix below
class(ecoRname1)
head(ecoRname1, 9)
# initialize summary tables
euc.summary <- matrix(NA, nrow=5, ncol=length(ecoRname1)+1) # initializing blank matrices to fill in the loop
dim(euc.summary)
colnames(euc.summary) <- c("ALL",ecoRname1) #indicates same assignment in each object
rownames(euc.summary) <- c("Min","Q1","Median","Q3","Max")
euc.summary

# Add all distances summary statistics to column 1 of the summary table (i.e. not by region)
euc.summary[,1] <- round(c( min(rdistmat1[rdistmat1!=0]), quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[2], median(rdistmat1[rdistmat1!=0]), quantile(rdistmat1[rdistmat1!=0], probs=seq(0,1, 0.25), names=F)[4], max(rdistmat1[rdistmat1!=0]) ),1)

print(euc.summary)

# Unsure that Springsteen function below will work as euc is an spDists created object that I think retained ecoregional & not sure that's so with rdistmat1
# Add within-region summary statistics to summary table 
# for (r in 1:length(ecoRname1)){ # loop through regions and fill in the matrices
#   euc.reg <- euc[grep(ecoRname1[r], rownames(euc)), grep(ecoRname1[r],colnames(euc))] # retrieving only columns and rows in the distance matrix that contain the same region code in their column/row name
#   # retrieving only columns and rows in the distance matrix that contain the same region code in their column/row name
#   euc.summary[, (r+1)] <- round(c( min(euc.reg[euc.reg!=0]), quantile(euc.reg[euc.reg!=0], probs=seq(0,1, 0.25), names=F)[2], median(euc.reg[euc.reg!=0]), quantile(euc.reg[euc.reg!=0], probs=seq(0,1, 0.25), names=F)[4], max(euc.reg[euc.reg!=0]) ),1)
# }

# Distances for all NLA sites
distmat_dg <- st_distance(dg.sf,dg.sf,by_element = FALSE)
rdistmat_dg <- distmat_dg[1:1185, ]
rdistmat1_dg <- as.vector(rdistmat_dg)

# initialize summary tables
euc.summary_dg <- matrix(NA, nrow=5, ncol=length(ecoRname1)+1) # initializing blank matrices to fill in the loop
dim(euc.summary_dg)
colnames(euc.summary_dg) <- c("ALL",ecoRname1) #indicates same assignment in each object
rownames(euc.summary_dg) <- c("Min","Q1","Median","Q3","Max")


euc.summary_dg[,1] <- round(c( min(rdistmat1_dg[rdistmat1_dg!=0]), quantile(rdistmat1_dg[rdistmat1_dg!=0], probs=seq(0,1, 0.25), names=F)[2], median(rdistmat1_dg[rdistmat1_dg!=0]), quantile(rdistmat1_dg[rdistmat1_dg!=0], probs=seq(0,1, 0.25), names=F)[4], max(rdistmat1_dg[rdistmat1_dg!=0]) ),1)

print(euc.summary_dg)

# brute force to get 5-number summary of ecoregions cut-n-paste ecoregions to get specific data frames:  cpl, nap, npl, sap, spl, tpl, umw, wmt, xer
names(dg.sf)

count(dg.sf, WSA9_NAME) %>% print(n = Inf)

# Get ecoregion-specific NLA sites
cpl <- dg.sf %>% filter(WSA9_NAME == "Coastal Plains")

distmat_cpl <- st_distance(cpl, cpl,by_element = FALSE)
dim(distmat_cpl)
rdistmat_cpl <- distmat_cpl[1:150, ] # change to match # sites/rows
rdistmat1_cpl <- as.vector(rdistmat_cpl)

round(min(rdistmat1_cpl[rdistmat1_cpl!=0]))
round(quantile(rdistmat1_cpl[rdistmat1_cpl!=0], probs=seq(0,1, 0.25), names=F)[2])
round(median(rdistmat1_cpl[rdistmat1_cpl!=0]))
round(quantile(rdistmat1_cpl[rdistmat1_cpl!=0], probs=seq(0,1, 0.25), names=F)[4])
round(max(rdistmat1_cpl[rdistmat1_cpl!=0]))

# GitHub question:  if I save a workspace, .RData, will that be pushed when I push to GitHub?  Or, should data frames go in #.gitignore?
# Jake - we are using a public github repo under the EPA enterprise license.  Anything we push to github can be downloaded by the public.  We should use the shared documents library at our SharePoint site for data.  Code can go to github.
```

## Lagged scatterplots
Note that can use simple feature object, such as cpl, for histogram, but spatial object needed for lagged scatterplots.  I took log10 transform to  get data somewhat unimodal and symmetric.
```{r, eval=FALSE, echo=FALSE, laggedscatterplot}
# cpl
cpl_sp <- as(cpl, "Spatial")
class(cpl_sp)
ggplot(cpl,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(cpl,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.ch4.umol~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.ch4.umol~1, cpl_sp, c(0, 10000, 25000, 50000, 150000, 250000, 500000))

ggplot(cpl,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(cpl,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.co2.umol~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(log10(dissolved.co2.umol)~1, cpl_sp, c(0, 10000, 25000, 50000, 150000, 250000, 500000))

ggplot(cpl,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(cpl,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(dissolved.n2o.nmol~1, cpl_sp, c(0, 50000, 150000, 250000, 500000, 1000000, 1500000))

hscat(log10(dissolved.n2o.nmol)~1, cpl_sp, c(0, 10000, 25000, 50000, 150000, 250000, 500000))

# nap # nap object doesn't exist
nap <- dg.sf %>% filter(WSA9_NAME == "Northern Appalachians")
nap_sp <- as(nap, "Spatial")
class(nap_sp)
ggplot(nap,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(nap,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.ch4.umol~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.ch4.umol)~1, nap_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(nap,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(nap,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.co2.umol~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.co2.umol)~1, nap_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(nap,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(nap,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.n2o.nmol~1, nap_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.n2o.nmol)~1, nap_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

# npl 
npl <- dg.sf %>% filter(WSA9_NAME == "Northern Plains")
npl_sp <- as(npl, "Spatial")
class(npl_sp)
ggplot(npl,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(npl,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.ch4.umol~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.ch4.umol)~1, npl_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(npl,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(npl,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.co2.umol~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.co2.umol)~1, npl_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(npl,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(npl,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(dissolved.n2o.nmol~1, npl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.n2o.nmol)~1, npl_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

# sap
sap <- dg.sf %>% filter(WSA9_NAME == "Southern Appalachians")
sap_sp <- as(sap, "Spatial")
class(sap_sp)
ggplot(sap,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(sap,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(dissolved.ch4.umol~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(log10(dissolved.ch4.umol)~1, sap_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(sap,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(sap,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(dissolved.co2.umol~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(log10(dissolved.co2.umol)~1, sap_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(sap,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(sap,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(dissolved.n2o.nmol~1, sap_sp, c(0, 10000, 50000, 150000, 300000, 450000, 650000))

hscat(log10(dissolved.n2o.nmol)~1, sap_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

# spl
spl <- dg.sf %>% filter(WSA9_NAME == "Southern Plains")
spl_sp <- as(spl, "Spatial")
class(spl_sp)
ggplot(spl,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(spl,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(dissolved.ch4.umol~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(log10(dissolved.ch4.umol)~1, spl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(spl,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(spl,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(dissolved.co2.umol~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(log10(dissolved.co2.umol)~1, spl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(spl,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(spl,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, spl_sp, c(0, 10000, 50000, 150000, 250000, 350000, 500000))

hscat(dissolved.n2o.nmol~1, spl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 400000))

hscat(log10(dissolved.n2o.nmol)~1, spl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

# tpl
tpl <- dg.sf %>% filter(WSA9_NAME == "Temperate Plains")
tpl_sp <- as(tpl, "Spatial")
class(tpl_sp)
ggplot(tpl,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(tpl,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(dissolved.ch4.umol~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(log10(dissolved.ch4.umol)~1, tpl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(tpl,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(tpl,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(dissolved.co2.umol~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(log10(dissolved.co2.umol)~1, tpl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

ggplot(tpl,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(tpl,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(dissolved.n2o.nmol~1, tpl_sp, c(0, 10000, 50000, 100000, 200000, 300000, 600000))

hscat(log10(dissolved.n2o.nmol)~1, tpl_sp, c(0, 25000, 50000, 75000, 100000, 125000, 150000))

# umw
umw <- dg.sf %>% filter(WSA9_NAME == "Upper Midwest")
umw_sp <- as(umw, "Spatial")
class(umw_sp)
ggplot(umw,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(umw,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, umw_sp, c(0, 10000, 50000, 75000, 100000, 200000, 350000))

hscat(dissolved.ch4.umol~1, umw_sp, c(0, 10000, 50000, 75000, 100000, 200000, 350000))

hscat(log10(dissolved.ch4.umol)~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

ggplot(umw,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(umw,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, umw_sp, c(0, 10000, 50000, 75000, 100000, 200000, 350000))

hscat(dissolved.co2.umol~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

hscat(log10(dissolved.co2.umol)~1, umw_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(umw,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(umw,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

hscat(dissolved.n2o.nmol~1, umw_sp, c(0, 25000, 50000, 75000, 100000, 250000, 350000))

hscat(log10(dissolved.n2o.nmol)~1, umw_sp, c(0, 25000, 50000, 100000, 200000, 300000, 400000))

# wmt
wmt <- dg.sf %>% filter(WSA9_NAME == "Western Mountains")
wmt_sp <- as(wmt, "Spatial")
class(wmt_sp)
ggplot(wmt,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(wmt,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(dissolved.ch4.umol~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(log10(dissolved.ch4.umol)~1, wmt_sp, c(0, 25000, 50000, 100000, 200000, 350000, 700000))

ggplot(wmt,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(wmt,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(dissolved.co2.umol~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(log10(dissolved.co2.umol)~1, wmt_sp, c(0, 25000, 50000, 100000, 200000, 350000, 700000))

ggplot(wmt,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(wmt,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(dissolved.n2o.nmol~1, wmt_sp, c(0, 10000, 50000, 100000, 200000, 350000, 700000))

hscat(log10(dissolved.n2o.nmol)~1, wmt_sp, c(0, 25000, 50000, 100000, 200000, 350000, 700000))

# xer
xer <- dg.sf %>% filter(WSA9_NAME == "Xeric")
xer_sp <- as(xer, "Spatial")
class(xer_sp)
ggplot(xer,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(xer,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
# 10 km bin/lag only has 2 points plotted so start with 50 km
hscat(log10(dissolved.ch4.umol)~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(dissolved.ch4.umol~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(log10(dissolved.ch4.umol)~1, xer_sp, c(0, 25000, 50000, 750000, 100000, 200000, 400000, 800000))

ggplot(xer,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(xer,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(dissolved.co2.umol~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(log10(dissolved.co2.umol)~1, xer_sp, c(0, 25000, 50000, 750000, 100000, 200000, 400000, 800000))

ggplot(xer,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(xer,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(dissolved.n2o.nmol~1, xer_sp, c(0, 50000, 100000, 200000, 400000, 800000))

hscat(log10(dissolved.n2o.nmol)~1, xer_sp, c(0, 25000, 50000, 750000, 100000, 200000, 400000, 800000))

# all
dg_sp <- as(dg.sf, "Spatial")
class(dg_sp)
ggplot(dg.sf,aes(dissolved.ch4.umol)) + geom_histogram()
ggplot(dg.sf,aes(dissolved.ch4.umol)) + geom_histogram() + scale_x_log10()
hscat(log10(dissolved.ch4.umol)~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(dissolved.ch4.umol~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(log10(dissolved.ch4.umol)~1, dg_sp, c(0, 10000, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(dg.sf,aes(dissolved.co2.umol)) + geom_histogram()
ggplot(dg.sf,aes(dissolved.co2.umol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.co2.umol)~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(dissolved.co2.umol~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(log10(dissolved.co2.umol)~1, dg_sp, c(0, 10000, 25000, 50000, 100000, 200000, 300000, 400000))

ggplot(dg.sf,aes(dissolved.n2o.nmol)) + geom_histogram()
ggplot(dg.sf,aes(dissolved.n2o.nmol)) + geom_histogram() + scale_x_log10()

hscat(log10(dissolved.n2o.nmol)~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(dissolved.n2o.nmol~1, dg_sp, c(0, 50000, 100000, 200000, 400000, 800000, 1500000))

hscat(log10(dissolved.n2o.nmol)~1, dg_sp, c(0, 10000, 25000, 50000, 100000, 200000, 300000, 400000))

```

## k-NN = 1 and Moran plots
As with the lagged scatter plots, I had to take a simple feature object and convert it to a spatial object so I could use the nearest-neighbor and Moran scatter plot functions from the spdep package.  A Moran plot is based on plotting the N~2~O variable, dissolved.n2o, of a focal point on the x-axis and the average dissolved.n2o of the neighboring points on the y-axis.  Moran scatter plots were made for each of the 9 ecoregions and 1 for all of the NLA sites.  For each plot, a neighborhood of points was defined by the maximum distance to first nearest neighbor.  A distance-based spatial relationship was used because many of the ecoregions have several non-contiguous polygons or areas, which prevents a contiguity-based spatial relationship from being used.  The slope of the line through the scatter plot of points measures spatial autocorrelation, with a positive slope indicating positive spatial autocorrelation.

The code below is to be run separately for each ecoregion.  The CPL, TPL, and UMW ecoregions show strong positive spatial autocorrelation.  Negative spatial autocorrelation occurs in the NPL ecoregion because of the maximum outlier at a South Dakota site.  The SPL and XER ecoregions show no evidence of spatial autocorrelation.  Interestingly, it appears that the ecoregions with the highest dissolved.n2o concentrations, CPL, TPL, and UMW, drive the national pattern.
```{r, knn_moran}
names(dg)
# also includ WSA9, WSA9_NAME feature
dg_1 <- select(dg,site.id:dissolved.n2o.nmol, WSA9, WSA9_NAME)
names(dg_1)
dg_1 <- clean_names(dg_1)
names(dg_1)
distinct(dg_1, wsa9)
# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg_1$map_lon_dd, latitude = dg_1$map_lat_dd)

dg_sf1 <- st_as_sf(dg_1, coords = c("map_lon_dd", "map_lat_dd"),crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting 

st_crs(dg_sf1)
glimpse(dg_sf1)
# Get ecoregion-specific NLA sites
## CPL
cpl <- dg_sf1 %>% filter(wsa9 == "CPL" & visit_no == 1 & sample_source == "DG")

cpl_sp <- as(cpl, "Spatial")
class(cpl_sp)

ds1coords <- coordinates(cpl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = cpl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=134761, row.names=cpl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(cpl_sp)
plot(ds1nb1, ds1coords, labels = cpl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(cpl)
# cpl_df <- st_drop_geometry(cpl)
# names(cpl_df)
summary(cpl$dissolved_n2o_nmol)

moran.plot(log(cpl$dissolved_n2o_nmol), listw = dsnb1.listw, labels = cpl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## NAP
nap <- dg_sf1 %>% filter(wsa9 == "NAP" & visit_no == 1 & sample_source == "DG")

nap_sp <- as(nap, "Spatial")
class(nap_sp)

ds1coords <- coordinates(nap_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = nap_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=112630, row.names=nap_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(nap_sp)
plot(ds1nb1, ds1coords, labels = nap_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(nap)
# nap_df <- st_drop_geometry(nap)
# names(nap_df)
summary(nap$dissolved_n2o_nmol)

moran.plot(log(nap$dissolved_n2o_nmol), listw = dsnb1.listw, labels = nap$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## NPL
npl <- dg_sf1 %>% filter(wsa9 == "NPL" & visit_no == 1 & sample_source == "DG")

npl_sp <- as(npl, "Spatial")
class(npl_sp)

ds1coords <- coordinates(npl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = npl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=215395, row.names=npl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(npl_sp)
plot(ds1nb1, ds1coords, labels = npl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(npl)
# npl_df <- st_drop_geometry(npl)
# names(npl_df)
summary(npl$dissolved_n2o_nmol)

moran.plot(log(npl$dissolved_n2o_nmol), listw = dsnb1.listw, labels = npl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## SAP
sap <- dg_sf1 %>% filter(wsa9 == "SAP" & visit_no == 1 & sample_source == "DG")

sap_sp <- as(sap, "Spatial")
class(sap_sp)

ds1coords <- coordinates(sap_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = sap_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=128285, row.names=sap_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(sap_sp)
plot(ds1nb1, ds1coords, labels = sap_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(sap)
# sap_df <- st_drop_geometry(sap)
# names(sap_df)
summary(sap$dissolved_n2o_nmol)

moran.plot(log(sap$dissolved_n2o_nmol), listw = dsnb1.listw, labels = sap$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## SPL
spl <- dg_sf1 %>% filter(wsa9 == "SPL" & visit_no == 1 & sample_source == "DG")

spl_sp <- as(spl, "Spatial")
class(spl_sp)

ds1coords <- coordinates(spl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = spl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=173395, row.names=spl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(spl_sp)
plot(ds1nb1, ds1coords, labels = spl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(spl)
# spl_df <- st_drop_geometry(spl)
# names(spl_df)
summary(spl$dissolved_n2o_nmol)

moran.plot(log(spl$dissolved_n2o_nmol), listw = dsnb1.listw, labels = spl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## TPL
tpl <- dg_sf1 %>% filter(wsa9 == "TPL" & visit_no == 1 & sample_source == "DG")

tpl_sp <- as(tpl, "Spatial")
class(tpl_sp)
nrow(zerodist(tpl_sp)) # indicates 1 pair of identical coordinates

(zerodist(tpl_sp)) # this gives the row numbers of the pair 30 & 36
View(tpl) # to view rows 30, site_id NLA17_IN-10002, & 36, NLA17_IN-10047

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(tpl_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = tpl_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=223893, row.names=tpl_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(tpl_sp)
plot(ds1nb1, ds1coords, labels = tpl_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(tpl)
# tpl_df <- st_drop_geometry(tpl)
# names(tpl_df)
summary(tpl$dissolved_n2o_nmol)

moran.plot(log(tpl$dissolved_n2o_nmol), listw = dsnb1.listw, labels = tpl$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## UMW
umw <- dg_sf1 %>% filter(wsa9 == "UMW" & visit_no == 1 & sample_source == "DG")

umw_sp <- as(umw, "Spatial")
class(umw_sp)
nrow(zerodist(umw_sp)) # indicates 1 pair of identical coordinates

(zerodist(umw_sp)) # this gives the row numbers of the pair 136 & 158
View(umw) # to view rows 136, site_id NLA17_WI-10027, & 158, NLA17_WI-10127

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(umw_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = umw_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=99590, row.names=umw_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(umw_sp)
plot(ds1nb1, ds1coords, labels = umw_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(umw)
# umw_df <- st_drop_geometry(umw)
# names(umw_df)
summary(umw$dissolved_n2o_nmol)

moran.plot(log(umw$dissolved_n2o_nmol), listw = dsnb1.listw, labels = umw$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## WMT
wmt <- dg_sf1 %>% filter(wsa9 == "WMT" & visit_no == 1 & sample_source == "DG")

wmt_sp <- as(wmt, "Spatial")
class(wmt_sp)

# nrow(zerodist(wmt_sp)) # indicates 1 pair of identical coordinates
# (zerodist(wmt_sp)) # this gives the row numbers of the pair 136 & 158
# View(wmt) # to view rows 136, site_id NLA17_WI-10027, & 158, NLA17_WI-10127

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(wmt_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = wmt_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=295987, row.names=wmt_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(wmt_sp)
plot(ds1nb1, ds1coords, labels = wmt_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(wmt)
# wmt_df <- st_drop_geometry(wmt)
# names(wmt_df)
summary(wmt$dissolved_n2o_nmol)

moran.plot(log(wmt$dissolved_n2o_nmol), listw = dsnb1.listw, labels = wmt$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## XER
xer <- dg_sf1 %>% filter(wsa9 == "XER" & visit_no == 1 & sample_source == "DG")

xer_sp <- as(xer, "Spatial")
class(xer_sp)

# nrow(zerodist(xer_sp)) # indicates 1 pair of identical coordinates
# (zerodist(xer_sp)) # this gives the row numbers of the pair 136 & 158
# View(xer) # to view rows 136, site_id NLA17_WI-10027, & 158, NLA17_WI-10127

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(xer_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = xer_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=259280, row.names=xer_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(xer_sp)
plot(ds1nb1, ds1coords, labels = xer_sp$site_id, add = TRUE)


dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(xer)
# xer_df <- st_drop_geometry(xer)
# names(xer_df)
summary(xer$dissolved_n2o_nmol)

moran.plot(log(xer$dissolved_n2o_nmol), listw = dsnb1.listw, labels = xer$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)

## NLA
nla <- dg_sf1 %>% filter(visit_no == 1 & sample_source == "DG")

nla_sp <- as(nla, "Spatial")
class(nla_sp)

nrow(zerodist(nla_sp)) # indicates 2 pairs of identical coordinates
(zerodist(nla_sp)) # this gives the row numbers of the pair (192 & 210:  NLA17_IN-10002 & NLA17_IN-10047) and the pair (1028 & 1054:  NLA17_WI-10027, & 158, NLA17_WI-10127)
# View(nla) 

# Warning message from code below:
# In knearneigh(ds1coords, k = 1) : knearneigh: identical points found

ds1coords <- coordinates(nla_sp)
ds1nb1 <- knn2nb(knearneigh(ds1coords, k=1), row.names = nla_sp$site_id)
# using the k=1 object to find the minimum distance at which all sites have a distance-based neighbor
dsnb1_dist <- unlist(nbdists(ds1nb1,ds1coords))
summary(dsnb1_dist)# use max distance from summary to assign distance to create neighbors

dsnb1 <- dnearneigh(ds1coords, d1=0, d2=259280, row.names=nla_sp$site_id, longlat=FALSE)
summary(dsnb1)

plot(nla_sp)
plot(ds1nb1, ds1coords, labels = nla_sp$site_id, add = TRUE)

dsnb1.listw <- nb2listw(dsnb1, style = "W")
summary(dsnb1.listw)

class(nla)
# nla_df <- st_drop_geometry(nla)
# names(nla_df)
summary(nla$dissolved_n2o_nmol)

moran.plot(log(nla$dissolved_n2o_nmol), listw = dsnb1.listw, labels = nla$site_id)
rm(ds1coords, ds1nb1, dsnb1, dsnb1.listw, dsnb1_dist)
```

## Correlograms: ncf and pgmirness packages
```{r, correlogram}

# Much of code below is based on example comparing correlograms among packages ncf, pgmirness, and spdep described in this chapter
# https://link.springer.com/chapter/10.1007/978-3-030-01989-1_5

coords <- data.frame(longitude = dg_1$map_lon_dd, latitude = dg_1$map_lat_dd)

dg_sf1 <- st_as_sf(dg_1, coords = c("map_lon_dd", "map_lat_dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting 

st_crs(dg_sf1)
names(dg_sf1)
nap_visit1 <- dg_sf1 %>% filter(wsa9 == "NAP" & visit_no == 1)
class(nap_visit1)
st_crs(nap_visit1)

nap_sp_visit1 <- as(nap_visit1, "Spatial")
class(nap_sp_visit1)

# trying ncf package which uses resampling to specify number of null permutations under the null to assess significance levels.  See if significance persist after increas resamp from 100 to 1000, which is the default.
# The x-intercept in the results is the distance at which objects are no more similar than expected by chance alone across the region.
# Run on CPL as that is giving correlation greater than 1, which according to Fletcher and Fortin might be due to small number of pairs of points used in that first distance bin or to outliers.  Perhaps, cluster of high Delaware sites (n visit 1 = 5) causes the correlation to be greater than 1.
# Looks like 71 pairs of points being used.
# With a lag, or bin distance, of 50 km only go out 10 bins, 500 km, and do a Bonferroni adjustment of 0.05/10 = 0.005
names(dg_1)
dg_cplvisit1 <- dg_1 %>% filter(wsa9 == "CPL" & visit_no == 1)
# N.B. default is resamp = 1000 so that can take 10 minutes for n =1090 sites
class(dg_cplvisit1)

correlo_n2o_ncf <- ncf::correlog(x = dg_cplvisit1$map_lon_dd, y = dg_cplvisit1$map_lat_dd, z = log(dg_cplvisit1$dissolved_n2o_nmol), increment = 50, resamp = 1000, latlon = TRUE)
names(correlo_n2o_ncf)
#plot(correlo_n2o_ncf) # works when pgmiress commented out


# B/c returns a list of list have to access with [[]]
print(correlo_n2o_ncf[["n"]])
print(correlo_n2o_ncf[["mean.of.class"]])
print(correlo_n2o_ncf[["correlation"]])
head(correlo_n2o_ncf[["mean.of.class"]])
plot(correlo_n2o_ncf[["mean.of.class"]], correlo_n2o_ncf[["correlation"]])

class(correlo_n2o_ncf)
#ncf::plot.correlog(correlo_n2o_ncf)

# CPL outlier check by working through all 10 pairwise removal of cluster of 5 high Delaware sites
out_cplvisit1 <- dg_1 %>% filter(wsa9 == "CPL" & visit_no == 1 & (site_id != "NLA17_DE-10003" & site_id != "NLA17_DE-10004"))

out_cplcorrelo_n2o <- ncf::correlog(x = out_cplvisit1$map_lon_dd, y = out_cplvisit1$map_lat_dd, z = log(out_cplvisit1$dissolved_n2o_nmol), increment = 50, resamp = 1000, latlon = TRUE)

#plot(out_cplcorrelo_n2o)
#rm(out_cplvisit1, out_cplcorrelo_n2o)

# trying pgirmess package uses library spdep including moran.test and geary.test functions.  Distances are euclidean and in the same units as the spatial coordinates.  As run below, using geographical coordinates in decimal degrees so are distance classes retuned in decimal degrees?
# what if run on a spatial points data frame?
# Uses normality assumption, which is faster, to assess significance
dg_napvisit1 <- dg_1 %>% filter(wsa9 == "NAP" & visit_no == 1)
coords_nap <- cbind(dg_napvisit1$map_lon_dd, dg_napvisit1$map_lat_dd)
correl_napn2o_pg <- pgirmess::correlog(coords_nap, log(dg_napvisit1$dissolved_n2o_nmol), method = "Moran", nbclass = NULL, alternative = "two.sided")

head(round(correl_napn2o_pg, 2))
tail(round(correl_napn2o_pg, 2))
plot(correl_napn2o_pg)

# apply to SpatialPointsDataFrame that has projected coordinates and believe returning distance classes in meters
coords_sp_nap <- coordinates(nap_sp_visit1)
correl_spnapn2o_pg <- pgirmess::correlog(coords_sp_nap, log(nap_sp_visit1@data$dissolved_n2o_nmol), method = "Moran", nbclass = 30, alternative = "two.sided")

head(round(correl_spnapn2o_pg, 2), 30)
tail(round(correl_spnapn2o_pg ,2))
plot(correl_spnapn2o_pg)
```

## Correlograms by Ecoregions
Doug Anderson wrote functions to deal with the list of list output from the correlog function in the ncf package.  He also wrote functions so that the correlogram of dissolved NO2 gas could be plotted by ecoregion using base plot, cowplot, or ggplot2 code.
```{r, correlogram_ecoregions}
# Original code from Doug Anderson at Neptune from file:  Neptune_correlogram_TDS05_Anderson.Rmd

# set the theme of the ggplot
theme_set(theme_bw()) # the theme I prefer is theme_bw()

## Can define a new function to plot
plot_correlog <- function(ncf_correlog, 
                          # names of list components
                          n_col = "n", 
                          mean_col = "mean.of.class",
                          cor_col = "correlation",
                          xint_col = "x.intercept",
                          pval_col = "p",
                          name_col = NULL, #can change to column that has names of interest
                          alpha = 0.05, # two sided significance level
                          # plot labels and adjustments
                          plot_title = "Correlogram", #can change to NULL
                          plot_subtitle = waiver(),
                          y_label = "Correlation",
                          x_label = "Distance (mean-of-class)",
                          pt_size = I(2), pt_color = "black",
                          ln_size = I(0.5), ln_color = "black", 
                          ln_type = "solid",
                          title_size = 14, subtitle_size = 14, 
                          axis_title_size = 14, axis_text_size = 14, 
                          title_color = "black", 
                          subtitle_color = "black",
                          axis_title_color = "black", 
                          axis_text_color = "black",
                          title_bold = TRUE, axis_bold = FALSE,
                          xaxis_color = "gray", xaxis_type = "solid",
                          theme_style = theme_bw()){
  # ncf_correlog is a list object exported from ncf::correlog() but can also be a dataframe with named columns
  
  # prepare a data set for plotting based on the list components or data frame columns
  dat <- data.frame(
    n = ncf_correlog[[n_col]],
    mean = ncf_correlog[[mean_col]],
    cor = ncf_correlog[[cor_col]],
    # xint = ncf_correlog[[xint_col]],
    pval = ncf_correlog[[pval_col]]
  )
  # create a variable to help plot the hollow and solid points
  # If a permutation test was performed, values significant at a nominal (two-sided) 5%-level 
  # will be represented by filled circles and non-significant values by open circles.
  dat$sig <- ifelse(dat$pval * 2 < alpha, TRUE, FALSE)
  
  ## Start the plot
  g <- ggplot(dat) +
    theme_style +
    geom_hline(yintercept = 0, color = xaxis_color, linetype = xaxis_type) +
    # geom_point(aes(x=mean, y=cor, shape=sig), size=pt_size, color=pt_color) +
    # geom_line(aes(x=mean, y=cor, group=1), size=ln_size, color=ln_color, linetype=ln_type) +
    lemon::geom_pointline(aes(x=mean, y=cor, shape=sig, group=1),
                          size = pt_size, color = pt_color, 
                          linetype = ln_type, linesize = ln_size, 
                          linecolor = ln_color) +
    scale_shape_manual(values=c("TRUE"=19, "FALSE"=1),
                       labels=c("TRUE"="Sig.", "FALSE"="Not Sig."),
                       guide=FALSE) +
    labs(x=x_label, y=y_label) 
  
  ## add a title
  if(!is.null(name_col)){#include a title if column for name is provided or list object has a list item for name
    if(!is.null(plot_title)){ #if plot_title is a string, separate the plot_title with the other name by a ':'
      nm <- unique(as.character(ncf_correlog[[name_col]]))
      g <- g + 
        ggtitle(label = paste(plot_title, ": ", nm, sep=""), subtitle = plot_subtitle)
    } else{ #if plot_title is null, only include the name
      nm <- unique(as.character(ncf_correlog[[name_col]]))
      g <- g + 
        ggtitle(label = nm, subtitle = plot_subtitle)
    }
  } else{ # if there is no name column, only include the plot_title of interest (can be NULL)
    g <- g + 
      ggtitle(label = plot_title, subtitle = plot_subtitle) 
  }
  
  ## modify theme
  g <- g + 
    theme(plot.title = element_text(size=title_size, 
                                    hjust=0.5, #change to a value between 0 (left) and 1 (right)
                                    face=ifelse(title_bold == TRUE, "bold", "plain"), 
                                    color=title_color),
          plot.subtitle = element_text(size=subtitle_size, 
                                       hjust=0.5, 
                                       color=subtitle_color),
          axis.title = element_text(size=axis_title_size, 
                                    face=ifelse(axis_bold == TRUE, "bold", "plain"), 
                                    color=axis_title_color),
          axis.text = element_text(size=axis_text_size, #?theme
                                   color=axis_text_color), #?element_text
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank())
  return(g)
}

dg_1 <- select(dg,site.id:map.lon.dd, dissolved.n2o.nmol, WSA9, WSA9_NAME, ONOFFNET, nitrate.n.result,chla.result.vol, max.bf, temp.surf, temp.bottom, o2.surf, o2.bottom, lake.orgn, state, size.cat)
names(dg_1)
dg_1 <- clean_names(dg_1)
names(dg_1)
dg_1 <- dg_1 %>% mutate(log_n2o = round(log(dissolved_n2o_nmol),3))
## Subset dg_1 by visit_no == 1
dg_visit1 <- dg_1 %>% dplyr::filter(visit_no == 1)

## Perform the same test for each wsa9 using Z = "log_n2o"
## Start by defining a function
ncf_correlog <- function(dat, # data to send to ncf::correlog
                         z_col, # name of the column in the dataset for water quality parameter
                         i = 50, # increment to be used in ncf::correlog
                         N = 1000, # number of resamples in ncf::correlog
                         x_col = "map_lon_dd", # name of the column in the dataset for longitude
                         y_col = "map_lat_dd", # name of the column in the dataset for latitude
                         lat_lon = TRUE, # if the x and y coordinates for ncf::correlog are lat and lon
                         rem_missing = FALSE, # argument of ncf::correlog
                         run_quietly = FALSE){ # argument of ncf::correlog
  library(ncf)
  
  X = dat[[x_col]] #grabs the x_col from data.frame
  Y = dat[[y_col]] #grabs the y_col from data.frame
  Z = dat[[z_col]] #grabs the z_col from data.frame
  
  ## Use ncf::correlog
  crlg <- ncf::correlog(x = X, y = Y, z = Z, 
                        increment = i, resamp = N, latlon = lat_lon, 
                        na.rm = rem_missing, quiet = run_quietly)
  return(crlg)
} 

## Split the dataframe by each wsa9: turns the data frame into a list 
##   where each list item is a data frame filtered to that wsa9
## lapply applies the function ncf_correlog on each list object (a data frame)
## the final product is a list of correlog objects
## this is similar to looping
## setting seed so get same result from permutations ncf::correlog function
set.seed(2035)
log_n2o_correlog_list <- dg_visit1 %>%
  split(.$wsa9) %>% # '.' means use the data frame that preceded this line
  lapply(function(x) ncf_correlog(dat = x, z_col = "log_n2o")) 
#ncf_correlog is the function name, 
#dat is the paramater that takes a data.frame,
#z_col is the parameter that takes a string name for a column of a water quality paramater

## look at the structure: list of 9 items where each item is a 
##   list containing 6 items: n, mean, correlation, x.int, p, call
str(log_n2o_correlog_list)

## Function to remove the list item 'call' which is of a different length 
##   than the other items (n, mean, correlation, x.int, and p)
## This function will also convert each list item to a dataframe
crlg_to_dat <- function(ncf_correlog, # ncf_correlog is a list object that was output from ncf::correlog
                        n_col = "n", 
                        mean_col = "mean.of.class",
                        cor_col = "correlation",
                        xint_col = "x.intercept",
                        pval_col = "p"){ 
  dat <- data.frame(
    n = ncf_correlog[[n_col]],
    mean = ncf_correlog[[mean_col]],
    cor = ncf_correlog[[cor_col]],
    xint = ncf_correlog[[xint_col]],
    pval = ncf_correlog[[pval_col]]
  )
  return(dat)
}

## log_n20_correlog_list is already a list so there is no need to split
log_n2o_correlog_dats <- lapply(log_n2o_correlog_list, 
                                function(x) crlg_to_dat(ncf_correlog = x))
str(log_n2o_correlog_dats) # each item in the list is now a dataframe

## combine into one dataframe to grab the wsa9 (notice the name no longer has an s at the end)

log_n2o_correlog_dat <- log_n2o_correlog_dats %>%
  dplyr::bind_rows(., .id = "wsa9")

str(log_n2o_correlog_dat)
head(log_n2o_correlog_dat)
## Make individual plots, the following object is a list containing a ggplot for each
log_n2o_correlog_plots <- log_n2o_correlog_dat %>%
  split(.$wsa9) %>% # splits the data frame by wsa9, which creates a list with 9 data frames
  lapply(function(x) plot_correlog(ncf_correlog = x, # use the data.frame for each wsa9 to make a plot
                                   plot_title = NULL,
                                   n_col = "n", 
                                   mean_col = "mean",
                                   cor_col = "cor",
                                   xint_col = "xint",
                                   pval_col = "pval",
                                   name_col = "wsa9",
                                   title_size = 14, 
                                   subtitle_size = 14, 
                                   axis_title_size = 14, 
                                   axis_text_size = 14))
## if hard to see writing run again but increase "title_size", "subtitle_size", "axis_title_size", "axis_text_size" as needed 

## Look at each piece individually or scroll through
length(log_n2o_correlog_plots) # shows 9 items
# log_n20_correlog_plots
log_n2o_correlog_plots$CPL #or log_n20_correlog_plots[["CPL"]] or log_n2o_correlog_plots[[1]]
# log_n2o_correlog_plots$NAP
# log_n2o_correlog_plots$NPL
# log_n2o_correlog_plots$SAP
# log_n2o_correlog_plots$SPL
# log_n2o_correlog_plots$TPL
# log_n2o_correlog_plots$UMW
# log_n2o_correlog_plots$WMT
# log_n2o_correlog_plots$XER

## cowplot package (or other) can be used to group them into a matrix plot
log_n2o_correlog_plotgrid <- 
  cowplot::plot_grid(plotlist=log_n2o_correlog_plots, ncol=3)
print(log_n2o_correlog_plotgrid) # click 'Zoom' in plots quadrant, takes a few seconds to render
## can save the plot using 
# cowplot::ggsave(filename = "FILENAME.png", #saves a png version of the figure to the working folder
#                 plot = log_n20_correlog_plotgrid)
## can change .png to other forms
## can play with scale, width, and height to adjust the output of the figure saved to the png file

## alternatively, can make a facet plot since log_n20_correlog_dat is a dataframe in the correct format
names(log_n2o_correlog_dat) #"n"    "mean" "cor"  "xint" "pval" "wsa9"

## create column to shape point, sig == TRUE means two-sided test < 0.05
log_n2o_correlog_dat$sig <- ifelse(log_n2o_correlog_dat$pval * 2 < 0.05,
                                   TRUE, FALSE) 
head(log_n2o_correlog_dat)
## can change wsa9 to a factor to arrange what order the plots are shown, otherwise default arranges them alphabetically
# log_n20_correlog_dat$wsa9 <- factor(log_n20_correlog_dat, 
#                                     levels = c("CPL", "NAP", "NPL", "SAP", "SPL", "TPL", "UMW", "WMT", "XER"))

## make facet plot
log_n2o_correlog_facetplot <- ggplot(log_n2o_correlog_dat) +
  geom_hline(yintercept = 0, color = "gray", linetype = "solid") +
  # geom_point(aes(x=mean, y=cor, shape=sig), size=I(2), color="black") +
  # geom_line(aes(x=mean, y=cor, group=1), size=I(0.5), color="black", linetype="solid") +
  lemon::geom_pointline(aes(x=mean, y=cor, shape=sig, group=1), 
                        size=I(2), color = "black", 
                        linetype = "solid", linesize = I(0.5), 
                        linecolor = "black") +
  scale_shape_manual(values=c("TRUE"=19, "FALSE"=1), 
                     labels=c("TRUE"="Sig.", "FALSE"="Not Sig."),
                     guide=FALSE) +
  facet_wrap(~wsa9, ncol=3, scales="free") +
  labs(x="Distance (mean-of-class)", y="Correlation") +
  theme_bw() +
  theme(plot.title = element_text(size=14, hjust=0.5, 
                                  face="bold", color="black"),
        plot.subtitle = element_text(size=14, hjust=0.5, color="black"),
        axis.title = element_text(size=14, face="plain", color="black"),
        axis.text = element_text(size=14, color="black"),
        strip.text = element_text(size=14, color="black", face="bold"),
        strip.background = element_rect(fill="gray", color="black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
print(log_n2o_correlog_facetplot)
## can save the plot using 
# cowplot::ggsave(filename = "FILENAME2.png", #saves a png version of the figure to the working folder
#                 plot = log_n20_correlog_facetplot) 
## can change .png to other forms
## can play with scale, width, and height to adjust the output of the figure saved to the png file



```



## Semivariograms
Variograms display the variability among pairs of points at various separation distances.  I was unable to fit a model to the dissolved gas concentration variograms using the default fitting parameters in gstat.  The variograms suggest a lack of spatial structure, but I suspect the model parameterization can be improved.

```{r, warning=FALSE, message=FALSE}

# Variogram function requires sp object
dg.sp <- as(dg.sf, Class = "Spatial")

# CO2 variogram
co2.v <- variogram(dissolved.co2.umol~1, dg.sp)
co2.v.fit <- fit.variogram(co2.v, vgm(c("Exp", "Mat", "Sph"))) # allow to choose best model.  Not sure which model warnings are associated with.
# co2.v.fit # chose sperical
co2.v.fit <- fit.variogram(co2.v, vgm("Sph")) # refit spherical, several warnings (?)

# CH4 variogram
ch4.v <- variogram(dissolved.ch4.umol~1, dg.sp)
ch4.v.fit <- fit.variogram(ch4.v, vgm(c("Exp", "Mat", "Sph"))) # allow to choose best model.  Not sure which model warnings are associated with.
# ch4.v.fit # chose exp
ch4.v.fit <- fit.variogram(ch4.v, vgm("Exp")) # refit exponential, no convergence

# N2O variogram
n2o.v <- variogram(dissolved.n2o.nmol~1, dg.sp)
n2o.v.fit <- fit.variogram(n2o.v, vgm(c("Exp", "Mat", "Sph"))) # allow to choose best model.  Not sure which model warnings are associated with.
# n2o.v.fit # chose exp
n2o.v.fit <- fit.variogram(n2o.v, vgm("Exp")) # refit exponential, no convergence


# Plot variograms and models (if fit)
plot(co2.v, model = co2.v.fit, main = "CO2 semivariogram")
plot(ch4.v, main = "CH4 semivariogram")
plot(n2o.v, main = "N2O semivariogram")

```

## Random Semivariograms
Empirical semivariograms were calculated for:  pH, total nitrogen (ntl), total phosphorous (ptl), and chloropyll a (chla).  In addition, semivariograms were calculated for the dissolved gasses:  DO, N2O, CH4, and CO2. We downloaded Chapter 8 code from https://asdar-book.org/ for generating random variograms.  An initial empirical, or sample, variogram is calculated and plotted for pH, with that object saved.  Then pH values are randomly sampled and assigned to the coordinates so that a random semivariogram can be calculated.  That is done 100 times, and the gray lines of the random semivariograms are plotted with the blue line of the empirical semivariogram. Semivariogram for pH shows evidence of spatial autocorrelation out to ~ 500 km compared to randomized semivariograms.

The water quality variables of pH, tnl, tpl, and chla showe strong evidence of spatial autocorrelation given the structure of their semivariograms versus randomized semivariograms.  The dissolved gasses, DO, N2O, CH4, and CO2 show none to modest spatial autocorrelation. The empirical semivariogram for surface dissolved oxygen is approximately a horizontal line, showing no evidence of spatial autocorrelation over the Euclidean distances that the lakes were sampled.  CH4 shows some autocorrelation to ~ 1000 km, but with no sill or leveling off the semivariance.
```{r, random_semivar}
names(dg)
dg_1 <- clean_names(dg)
names(dg_1)
# dropped onoffnet variable as I don't think it occurs in this version of the data frame, dg.2021-01-14.RData
dg_1 <- filter( dg_1, sample_source == "DG")

dg_1 <- select(dg_1,site_id:date_col, map_lat_dd, map_lon_dd, dissolved_co2_umol, dissolved_ch4_umol, dissolved_n2o_nmol, co2_sat_ratio, ch4_sat_ratio, n2o_sat_ratio, ag_eco9, ag_eco9_nm, nitrate_n_result, chla_result, ntl_result, ph_result, ptl_result,max_bf, temp_surf, temp_bottom, o2_surf, o2_bottom, lake_orgn, pstl_code , area_cat6, silica_result, calcium_result, visit_no) %>% filter(visit_no == 1 & ag_eco9 != "AK")

names(dg_1)
str(dg_1)

# To enable spatial analysis of the data, the dataframe will be converted to a 'simple features' (sf) object.
# Define coordinates
coords <- data.frame(longitude = dg_1$map_lon_dd, latitude = dg_1$map_lat_dd)

dg_sf1 <- st_as_sf(dg_1, coords = c("map_lon_dd", "map_lat_dd"), 
                  crs = 4269) %>% # standard for lat/lon
  st_transform(5070) # project to CONUS ALBERS for plotting 

st_crs(dg_sf1)
## pH
hist(dg_sf1$ph_result)

z_ph_sf1 = variogram(ph_result~1, dg_sf1)
plot(z_ph_sf1)
# plot(z_ph_sf1, plot.numbers = TRUE)
# plot(z_ph_sf1, ylab = "NLA ph Semivariance")
# plot(z_ph_sf1, cex = 0.5, type = "b", pch = 20, asp = 1, xlab = "Distance (meters)", ylab = "NLA ph semivariance")
# z_ph_plot1 <- plot(z_ph_sf1, cex = 0.5, type = "b", pch = 20, asp = 1, xlab = "Distance (meters) ")

print(xyplot(gamma ~ dist, z_ph_sf1, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf1$random = sample(dg_sf1$ph_result)
                     v = variogram(random ~ 1, dg_sf1)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 0.8), xlab = 'distance', ylab = 'pH semivariance'
))

# used Cressie's robust variogram b/c skewness and not wanting to transform pH as it is already on a log scale
z_cressie_ph <- variogram(ph_result~1, dg_sf1, cressie = TRUE)
plot(variogram(ph_result~1, dg_sf1, cressie = TRUE))

print(xyplot(gamma ~ dist, z_cressie_ph, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf1$random = sample(dg_sf1$ph_result)
                     v = variogram(random ~ 1, dg_sf1, cressie = TRUE)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 0.8), xlab = 'distance', ylab = 'pH semivariance'
))

## NTL
summary(dg_sf1$ntl_result) #no NA's

filter(dg_1,(!is.na(ntl_result))) %>% ggplot(., aes(ntl_result)) + geom_histogram()

# log transformation ~ unimodal & symmetric
filter(dg_1,(!is.na(ntl_result))) %>% ggplot(., aes(log(ntl_result))) + geom_histogram()

# hist(dg_sf1$ntl_result)
# hist(log(dg_sf1$ntl_result))

# default cutoff and width and no transformation
z_lntl_sf1 = variogram(log(ntl_result) ~ 1, dg_sf1)
plot(z_lntl_sf1, ylab = "NLA NTL Semivariance")
# set ylim for random semivariograms based on this plot

# cutoff and width from King et al. paper still not working even with tranform
z1_ntl_king = variogram(log(ntl_result) ~1, dg_sf1, cutoff=2500, width=20)
plot(z1_ntl_king)

# plot(z_ph_sf1, plot.numbers = TRUE)
# plot(z_ph_sf1, ylab = "NLA ph Semivariance")
# plot(z_ph_sf1, cex = 0.5, type = "b", pch = 20, asp = 1, xlab = "Distance (meters)", ylab = "NLA ph semivariance")
# z_ph_plot1 <- plot(z_ph_sf1, cex = 0.5, type = "b", pch = 20, asp = 1, xlab = "Distance (meters) ")

print(xyplot(gamma ~ dist, z_lntl_sf1, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf1$random = sample(dg_sf1$ntl_result)
                     v = variogram(log(random) ~ 1, dg_sf1)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 1.2), xlab = 'distance', ylab = 'NTL semivariance'
))

## PTL
summary(dg_sf1$ptl_result) # no NA's

filter(dg_sf1,(!is.na(ptl_result))) %>% ggplot(., aes(ptl_result)) + geom_histogram()

# log transformation ~ unimodal & symmetric
filter(dg_sf1,(!is.na(ptl_result))) %>% ggplot(., aes(log(ptl_result))) + geom_histogram()

# hist(log(dg_sf1$ntl_result))

z_lptl_sf1 = filter(dg_sf1, (!is.na(ptl_result))) %>% variogram(log(ptl_result)~1, .)
plot(z_lptl_sf1, ylab = "NLA TP Semivariance")
# set ylim of random semivariograms based on this plot
# plot(z_ph_sf1, plot.numbers = TRUE)

# data frame with no NA's
# dg_sf2 <- filter(dg_sf1, (!is.na(ptl_result)))

print(xyplot(gamma ~ dist, z_lptl_sf1, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf1$random = sample(dg_sf1$ptl_result)
                     v = variogram(log(random) ~ 1, dg_sf1)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 2), xlab = 'distance', ylab = 'TP semivariance'
))

## CHLA
summary(dg_sf1$chla_result) # no NA's

filter(dg_sf1,(!is.na(chla_result))) %>% ggplot(., aes(chla_result)) + geom_histogram()

# log transformation not that great but use for now
filter(dg_sf1,(!is.na(chla_result))) %>% ggplot(., aes(log(chla_result))) + geom_histogram()

# hist(log(dg_sf1$ntl_result))

z_lchla_sf1 = filter(dg_sf1, (!is.na(chla_result))) %>% variogram(log(chla_result)~1, .)
plot(z_lchla_sf1, ylab = "NLA CHLA Semivariance")
# set ylim of random semivariograms based on this plot
# plot(z_ph_sf1, plot.numbers = TRUE)

# data frame with no NA's
# dg_sf2 <- filter(dg_sf1, (!is.na(chla_result)))

print(xyplot(gamma ~ dist, z_lchla_sf1, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf1$random = sample(dg_sf1$chla_result)
                     v = variogram(log(random) ~ 1, dg_sf1)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 2.5), xlab = 'distance', ylab = 'CHLa semivariance'
))

## DO
summary(dg_sf1$o2_surf) # have 4 NA's

filter(dg_1,(!is.na(o2_surf))) %>% ggplot(., aes(o2_surf)) + geom_histogram()

# log probably too strong of transformation but use for now
filter(dg_1,(!is.na(o2_surf))) %>% ggplot(., aes(log(o2_surf))) + geom_histogram()

# hist(log(dg_sf1$ntl_result))

z_ldo_sf1 = filter(dg_sf1, (!is.na(o2_surf))) %>% variogram(log(o2_surf)~1, .)
# plot(z_ldo_sf1)
# plot(z_ph_sf1, plot.numbers = TRUE)
plot(z_ldo_sf1, ylab = "NLA Surface DO Semivariance")

# data frame with no NA's
dg_sf2 <- filter(dg_sf1, (!is.na(o2_surf)))

print(xyplot(gamma ~ dist, z_ldo_sf1, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf2$random = sample(dg_sf2$o2_surf)
                     v = variogram(log(random) ~ 1, dg_sf2)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 0.12), xlab = 'distance', ylab = 'NLA DO semivariance'
))

## N2O
summary(dg_sf1$dissolved_n2o_nmol) # no NA's

filter(dg_sf1, (!is.na(dissolved_n2o_nmol))) %>% ggplot(., aes(dissolved_n2o_nmol)) + geom_histogram()

# unimodal, but not symmetrical
filter(dg_sf1, (!is.na(dissolved_n2o_nmol))) %>% ggplot(., aes(log(dissolved_n2o_nmol))) + geom_histogram()

z_n2o_sf1 <- filter(dg_sf1, (!is.na(dissolved_n2o_nmol))) %>% variogram(log(dissolved_n2o_nmol) ~1, .)
plot(z_n2o_sf1, ylab = "N2O Semivariance")

# change cutoff and width
z_n2o = filter(dg_sf1, (!is.na(dissolved_n2o_nmol))) %>% variogram(log(dissolved_n2o_nmol)~1, ., cutoff = 750000, width = 25000)
# plot(z_n2o, ylab = "N2O Semivariance", plot.numbers = TRUE)
plot(z_n2o, ylab = "NLA N2O Semivariance")

print(xyplot(gamma ~ dist, z_n2o, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
    panel = function(x, y, ...) {
        for (i in 1:100) {
            dg_sf1$random = sample(dg_sf1$dissolved_n2o_nmol)
            v = variogram(log(random) ~ 1, dg_sf1, cutoff = 750000, width = 25000)
            llines(v$dist, v$gamma, col = 'grey')
        }
        panel.xyplot(x, y, ...)
    },
    ylim = c(0, 0.35), xlab = 'distance', ylab = 'N2O semivariance'
))

## CH4
summary(dg_1$dissolved_ch4_umo) # no NA's

filter(dg_1,(!is.na(dissolved_ch4_umol))) %>% ggplot(., aes(dissolved_ch4_umol)) + geom_histogram()

# log transformation looks good, ~ unimodal & symmetric
filter(dg_1,(!is.na(dissolved_ch4_umol))) %>% ggplot(., aes(log(dissolved_ch4_umol))) + geom_histogram()

z_lch4_sf1 = filter(dg_sf1, (!is.na(dissolved_ch4_umol))) %>% variogram(log(dissolved_ch4_umol)~1, .)
plot(z_lch4_sf1, ylab = "NLA CH4 Semivariance")
# change ylim below in random semivariogram based on this plot
# plot(z_ph_sf1, plot.numbers = TRUE)


# data frame with no NA's for random sampling below
# dg_sf2 <- filter(dg_sf1, (!is.na(dissolved_ch4_umol)))

print(xyplot(gamma ~ dist, z_lch4_sf1, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf1$random = sample(dg_sf1$dissolved_ch4_umol)
                     v = variogram(log(random) ~ 1, dg_sf1)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 2), xlab = 'distance', ylab = 'NLA CH4 semivariance'
))

## CO2
summary(dg_1$dissolved_co2_umo) # no NA's

filter(dg_1,(!is.na(dissolved_co2_umol))) %>% ggplot(., aes(dissolved_co2_umol)) + geom_histogram()

# log transformation, unimodal and symmetric
filter(dg_1,(!is.na(dissolved_co2_umol))) %>% ggplot(., aes(log(dissolved_co2_umol))) + geom_histogram()

# hist(log(dg_sf1$ntl_result))

z_lco2_sf1 = filter(dg_sf1, (!is.na(dissolved_co2_umol))) %>% variogram(log(dissolved_co2_umol)~1, .)
plot(z_lco2_sf1, ylab = "NLA CO2 Semivariance")
# change ylim in random semivariogram based on this plot
# plot(z_ph_sf1, plot.numbers = TRUE)

# data frame with no NA's
# dg_sf2 <- filter(dg_sf1, (!is.na(dissolved_co2_umol)))

print(xyplot(gamma ~ dist, z_lco2_sf1, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
             panel = function(x, y, ...) {
                 for (i in 1:100) {
                     dg_sf1$random = sample(dg_sf1$dissolved_co2_umol)
                     v = variogram(log(random) ~ 1, dg_sf1)
                     llines(v$dist, v$gamma, col = 'grey')
                 }
                 panel.xyplot(x, y, ...)
             },
             ylim = c(0, 1.2), xlab = 'distance', ylab = 'NLA CO2 semivariance'
))

```

# Exploratory analysis of N2O data
The mean N2O saturation ratio for the country is `r pop.eco.sat %>% filter(type == "National", subpopulation == "National", indicator == "N2O_SAT_RATIO") %>% select(estimate) %>% pull() %>% round(2)` (95% CI = `r pop.eco.sat %>% filter(type == "National", subpopulation == "National", indicator == "N2O_SAT_RATIO") %>% select(lcb95pct) %>% pull() %>% round(2)` - `r pop.eco.sat %>% filter(type == "National", subpopulation == "National", indicator == "N2O_SAT_RATIO") %>% select(ucb95pct) %>% pull() %>% round(2)`), suggesting that US waterbodies are a new N2O sink during the NLA index period.  This finding is consistent with a recent report that 67% of 101 agricultural ponds in Canada were undersaturated in N2O during the summer (Webb et al. 2019, PNAS).

There are several sources of N2O in surface waters.  The overlying atmosphere contains trace quantities of N2O (~300 ppb) that dissolve into surface waters as a function of barometric pressure and water temperature.  N2O is also produced and consumed in aquatic ecosystems via denitrification.  Denitrification is the reduction of oxidized forms of N (i.e. NO3) to more reduced forms (i.e. N2).  It is a form of anaerobic respiration where oxidized forms of N serve as the electron acceptor in the absence of more energetically favorable alternatives, such as oxygen.  N2O concentrations/fluxes are therefore somewhat dependent upon the availability of oxidized N and low dissolved oxygen.  N2O can also be produced via nitrification.  Nitrification is the aerobic oxidation of NH4 to more oxidized forms.  N2O can be produced as a byproduct during the process and rates are somewhat dependent upon the availability of ammonium.  See Beaulieu et al. 2011, 2014, and 2015 for more information. 

The effect of denitrification and nitrification on dissolved N2O concentrations near the air-water interface is somewhat mediated by hydrology.  Denitrification is an anaerobic process that occurs predominantly in the sediment or anoxic hypolimnion.  Therefore, N2O must advect or diffuse from the sediment/hyoplimion to the water surface before it can affect dissolved N2O concentration near the air/water interface (where NLA samples were collected).  Previous invesitgations have interpretted correlations between N2O and lake size and degree of thermal stratification as indicative of hydrologic control (DelSontro et al. 2019, Webb et al. 2019).

DelSontrol et al. (2019) reported that N2O emission rates were positively related to chl a.  The authors (inlcuding me, I'm one of the 'authors'!) speculate that chla is a surrogate for labile carbon.  Denitrification requires carbon, so perhaps high rates of denitrification-N2O production occur in the presence of abundant carbon availability.

We do not yet have depth profiles of DO or temperature.  When these data become available, we can include bottom water DO and strength of thermal stratification in the model.  For now, we can explore correlations with the following variables.  

* MeanDUsed - mean depth  
* ph.result - pH  
* nitrate.n.result - NO3-N (mg/L)  
* ntl.lab.result - total nitrogen (mg/L)  
* chla.result.vol - chlorophyll a (ug/L)  
* ptl.lab.result - total phosphorus (mg/L)  
* surftemp - surface water temperature (C)  

A correlation matrix of dissolved N2O concentration and potential controlling variables doesn't show any striking relationships, though the strongest relationship is with nitrate.  

```{r}
library(corrr)
dg_1 %>%
  select(index_site_depth, dissolved_n2o_nmol, ph_result, nitrate_n_result, ntl_result, chla_result, ptl_result, temp_surf) %>%
  correlate()
```

Categorization and regression analysis (CART), which can accomodate non-linear and interactive relationships, also identified nitrate as the most important predictor variable.  The CART analysis did not identify splits associated with ecoregion.

```{r}
library(tree)
model <- tree(dissolved.n2o.nmol ~ MeanDUsed + nitrate.n.result + ntl.lab.result + chla.result.vol + ptl.lab.result + surftemp + WSA9, data = dg)

plot(model)
text(model)
```
