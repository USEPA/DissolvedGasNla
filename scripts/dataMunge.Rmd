---
title: "Data Munging"
authors: "J. Beaulieu, R. Martin, and M. McManus"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    fig_caption: yes
    depth: 2
    number_sections: true
editor_options: 
  chunk_output_type: console
---
```{r results='hide', message=FALSE, warning=FALSE, echo=FALSE}
# load libraries
library(plyr) # for ddply, load before tidyverse
library(tidyverse) # dplyr, ggplot
library(forcats) # fct_explicit_na()
library(rLakeAnalyzer) # for buoyancy frequency

# Identify local path for each user
localPath <- Sys.getenv("USERPROFILE")
```


# Purpose
The purpose of this .rmd is to prepare the data set for subsequent modeling.  The data will be written as .RData object and stored at the shared documents library associated with this project: https://usepa.sharepoint.com/sites/ORD_NLA17_Dissolved_Gas

The dissolved gas data were currated in the 'NLA' dissolved gas project in RStudio.  The code can be found at a private github repository (https://github.com/USEPA/NLA).  After aggregating across duplicate samples, the data were written to nla17gasDataAggregated_2020-02-24.txt.  Data on waterbody surface area and design weights were provided by Karen Blocksom on 12/13/2019.  These data files are stored in the documents library associated with the 'ORD NLA17 Dissolved Gas' Private Group on SharePoint (https://usepa.sharepoint.com/sites/ORD_NLA17_Dissolved_Gas).  When synced to a local computer, the documents library can be read directly with R, after identifying the local directory path.

# Data
## Read data
Below we read in the data files.  

```{r}
# Read dissolved gas data file
dg <- read.table(file = paste0(localPath, 
                               "/Environmental Protection Agency (EPA)/",
                               "ORD NLA17 Dissolved Gas - Documents/",
                               "inputData/nla17gasDataAggregated_2020-02-24.txt"),
                 header = TRUE, sep = "\t", as.is = TRUE) 

# Read site weights and waterbody area data
wt.area <- read.csv(file = paste0(localPath, 
                               "/Environmental Protection Agency (EPA)/",
                               "ORD NLA17 Dissolved Gas - Documents/",
                               "inputData/NLA17_SiteWeights_Areas.csv"),
                    as.is = TRUE)

# Read in temp profile data
temp.o2 <- read.csv(file = paste0(localPath, 
                               "/Environmental Protection Agency (EPA)/",
                               "ORD NLA17 Dissolved Gas - Documents/",
                               "inputData/NLA17_Profile_Data_Updated_11Feb2020.csv"),
                    as.is = TRUE)
```

## Merge dissolved gas with survey weights + area
Unique waterbodies are identified by 'site id'.  Some waterbodies were visited twice, therefore each unique sampling trip is identified by a combination of 'site id' and visit number.  

``` {r}
dg %>% distinct(site.id, visit.no)
```

Survey weights and lake area are invariant across site visits, therefore the weights + lake area file does not contain a visit number field:
``` {r}
# no visit number in this file
names(wt.area)
```


The two data sets will be merged on the 'site id' fields.  The dissolved gas file contains data from sites in Alaska that are not present in the weights + lake area file.  Alaska sites are not an offical component of the NLA and will removed from this analysis.
``` {r}
# Will merge datasets on SITE_ID field.  Are all site.id values in dg present in wt.area?
dg %>% filter(!(site.id %in% wt.area$SITE_ID)) %>% distinct(site.id) # no.

# Remove AK sites
dg <- dg %>% filter(!(grepl("AK", site.id))) # exlclude alaska
```


There are 23 observations in the weights + lake area file that are absent from the dissolved gas file.  One observation is from Arizona.  This corresponds to notes in the chain of custody form indicating the vials arrived unlabeled and were not run.  The remaining sites are from OR. Karen Blocksom confirmed that these sites were part of the OR state survey, but collected 'most' of the NLA measurements.  They were included in the final NLA dataset for 'the purpose of adjusting weights'.  They did not collect gas samples and can be disregarded for this analysis.

``` {r}
# Any site id values in wt.area, but not present in dg?
wt.area %>% filter(!(SITE_ID %in% dg$site.id)) %>% select(SITE_ID, EVAL_CAT, SITETYPE) # 23 sites w/out dissolved gas data
```

Finally, lets merge these two files on site id.  Use left_join to retain all dissolved gas data, but disregard OR and AZ sites where we don't have gas data.
``` {r}
dim(dg) # 2369, 364

dg <- left_join(dg, wt.area, by = c("site.id" = "SITE_ID"))

dim(dg) # 2369, 369;  good retained all DG observations, added a few columns.
```


## Manipulate
Impliment unit conversion and create source/sink column:
``` {r}
dg <- dg %>%
  # unit conversion
  mutate(dissolved.ch4 = dissolved.ch4 * 1000000, # mol/L -> umol/L
         dissolved.co2 = dissolved.co2 * 1000000, # mol/L -> umol/L,
         dissolved.n2o = dissolved.n2o * 1000000000, # mol/L -> nmol/L
         # add source/sink column
         co2.src.snk = ifelse(co2.sat.ratio > 1, "source", "sink"),
         ch4.src.snk = ifelse(ch4.sat.ratio > 1, "source", "sink"),
         n2o.src.snk = ifelse(n2o.sat.ratio > 1, "source", "sink"))
```

The survey design is stratified by State.  Within each state, an unequal probability category based on 5 lake size classes is used.  Use lake area data provided by Karen to define lake area categories.
```{r}
dg <- dg %>%
  mutate(
    # add state
    state = substr(site.id, 7, 8),
    size_cat = factor( cut( AREA_HA,
                            breaks = c( -Inf, 4, 10, 20, 50, Inf ),
                            labels = c( "min_4", "4_10", "10_20", "20_50", "50_max") ) )
    )

```
All observations have a value for the size_cat design variable.

``` {r}
table(dg$size_cat, useNA = "ifany")
```


## Calculate dissolved oxygen and stratification indices from profile data
Water temperature and dissolved oxygen profiles were measured at the index site in each waterbody.  A variety of metrics describing the degree of thermal stratification can be extracted from these data.  Webb et al. used the Brunt–Väisälä buoyancy frequency as an indicator of thermal stratification strength.  We will do the same here.

Three site visits contain only NA for temperature.  Four site visits contain only NA for do.  Two of the incidents include notes that sonde was forgotten or malfunctioning. Two of the three sites were revisited later in the study and temperature data were collected.  Lets assign data from the second site visit to the first visit when no temperature data were collected.  This leaves only NLA17_CA-10082, visit 1, without temperature data.  NLA17_ID-10084 has no DO data and was not resampled.  Data sheet comment "Probe not measuring LDO for all depths".

```{r}
# Sites that only contain NAs.
missing <- temp.o2 %>% group_by(SITE_ID, VISIT_NO) %>% 
  summarise(all.temp = all(is.na(TEMPERATURE)),
            all.do = all(is.na(OXYGEN))) %>% 
  filter(all.temp == TRUE | all.do == TRUE) %>%
  select(SITE_ID, VISIT_NO, all.temp, all.do)

# View sites with missing temp/do
missing

# Two of the sites have data from second site visit
temp.o2 %>% filter(SITE_ID %in% missing$SITE_ID) %>%
  select(SITE_ID, VISIT_NO, TEMPERATURE, OXYGEN) 

# Extract data from second visit to assign to first visit
replacementData <- temp.o2 %>% filter(SITE_ID %in% missing$SITE_ID, VISIT_NO == 2) %>%
  select(SITE_ID, VISIT_NO, DEPTH, TEMPERATURE, OXYGEN) %>%
  mutate(VISIT_NO = 1) # change visit no to one for join

# Join the data
temp.o21 <- full_join(temp.o2, replacementData)

# Inspect results of join.  Looks good.  
# Only one site missing temperature and DO data. (NLA17_CA-10082)
# One site missing all DO data (NLA17_ID-10084)
temp.o21 %>% filter(SITE_ID %in% missing$SITE_ID) %>%
  select(SITE_ID, VISIT_NO, DEPTH, TEMPERATURE, OXYGEN) %>% 
  arrange(SITE_ID, VISIT_NO, DEPTH, TEMPERATURE, OXYGEN)

```

The field crews measured temperature/DO starting near the water surface, then at increasing depths.  A second measurement was made at the water surface before the sonde was removed from the water, therefore the file contains duplicate measurements at the shallowest depths. Duplicate measurements corrupt the buoyancy frequency function and will therefore be aggregated. 
``` {r}
# Aggregate across SITE_ID, VISIT_NO, and DEPTH.  I don't like the dplyr solution for this (group_map) and I'm not familiar with the purr::map_ functions.  I'm going old-school and busting out the trusty plyr::ddply.
temp.o2.2 <- temp.o21 %>% select(SITE_ID, VISIT_NO, DEPTH, TEMPERATURE, OXYGEN) %>%
  plyr::ddply(., .(SITE_ID, VISIT_NO, DEPTH), summarize, 
              TEMPERATURE.M = mean(TEMPERATURE, na.rm = TRUE),
              OXYGEN.M = mean(OXYGEN, na.rm = TRUE))


dim(temp.o21) # 11003
dim(temp.o2.2) # 10133, 870 observations aggregated
```

Finally, calculate the buoyancy frequency depth profile for each waterbody and print to buoyancyFrequency.pdf for inspection.  

``` {r}
# The buoyancy frequency is calculated at multiple depths, but at fewer depths than the where 
# temperature was measured.  The output of the buoyancy frequency function is shorter 
# than the input, which is incompatible with dplyr mutate and summarize.  The dplyr alternative
# is group_map which produces a list, but the grouping variables are stripped from the list
# elements.  I really don't like this.  I think this can be addressed by combining group_map
# with purr::map_ functions, but I'm not familiar with purr.  Rather, I'll use the old school
# split -lapply - do(rbind) approach.

# First, strip out any NA, NaN, Inf...etc


bf <- temp.o2.2 %>%
  filter(is.finite(TEMPERATURE.M)) %>% # This completely removes the CA site with only NA for temp data.
  group_split(SITE_ID, VISIT_NO) %>% # split into list of df
  lapply(function(x) {
    data.frame(BF = buoyancy.freq(wtr = x$TEMPERATURE.M, depths = x$DEPTH), # calculate buoyance frequency
               SITE_ID = unique(x$SITE_ID), # add site ID
               VISIT_NO = unique(x$VISIT_NO), # add visit no
               stringsAsFactors = FALSE)}) %>% 
  lapply(function(x) x %>% mutate(DEPTHS.BF = attr(BF, "depths"))) %>% # depths stored as attribute, assign to column
  do.call("rbind", .) # collapse to df

# there are three non-finite bf values, lets have a look
bf.na <- bf %>% filter(!is.finite(BF)) %>%
  select(SITE_ID, VISIT_NO) %>%
  mutate(SITE.VISIT = paste0(SITE_ID, VISIT_NO))

bf.na

# These site have a single temp measurement made at shallow depths (<1m).  Presumably these are 
# shallow sites, therefore unlikely to be stratified.  Assign a bf very close to 0 (see below)
bf %>% filter(paste0(SITE_ID, VISIT_NO) %in% bf.na$SITE.VISIT) 
temp.o2.2 %>% filter(paste0(SITE_ID, VISIT_NO) %in% bf.na$SITE.VISIT)

# plot buoyancy frequency depth profile
# (http://stackoverflow.com/questions/8018961/connect-points-in-qplot-by-adjacent-y-value-not-x-value)
# https://stackoverflow.com/questions/29034863/apply-a-ggplot-function-per-group-with-dplyr-and-set-title-per-group
bf.plot <- bf %>%
  group_by(SITE_ID, VISIT_NO) %>%
  do(plots = ggplot(data = .) +
       aes(DEPTHS.BF, BF) +
    geom_point() +
    geom_line() +
    scale_x_reverse() +
    coord_flip() +
    ggtitle(paste(unique(.$SITE_ID), "VISIT_NO = ", unique(.$VISIT_NO))))


# pdf("output/figures/buoyancyFrequency.pdf", onefile = TRUE)
# bf.plot$plots
# dev.off()
```

Webb et al. used the maximum buoyancy frequency value as an index of thermal stratification.  The maximum value should occur near the thermocline.  Here is an example of a classical pattern:
```{r}
bf.plot$plots[92]
```

Extract the max buoyancy frequency value for each waterbody after converting negative BF values to 0, per Webb.
``` {r}
# Finally, extract max buoyancy for each SITE_ID x VISIT_NO
bf.max <- bf %>% 
  mutate(BF = ifelse(BF < 0,
                     0,
                     BF)) %>%
  group_by(SITE_ID, VISIT_NO) %>%
  summarise(MAX.BF = max(BF, na.rm = TRUE)) %>%
  ungroup()
```

`r bf.max %>% summarize(n.na = sum(!is.finite(bf.max$MAX.BF))) %>% pull()` of the site have a non-finite value for maximum buoyancy frequency value.  These are the three shallow sites with only a single temperature measurement.  Assign these the minimum bf.max value.
``` {r}
bf.max %>% filter(!is.finite(MAX.BF))

min.max.bf <- bf.max %>% 
  filter(is.finite(MAX.BF)) %>%
  summarize(min.max.bf = min(MAX.BF))

bf.max <- bf.max %>%
  mutate(MAX.BF = replace(MAX.BF, 
                          !is.finite(MAX.BF), # if not finite
                          min.max.bf$min.max.bf)) # then min

# that took care of it
bf.max %>% filter(!is.finite(MAX.BF))
```


Finally, merge buoyancy frequency data with dg.  The buoyancy frequency data contains information from the extra Oregon sites (see above) and the AZ site where the gas samples were unlabeled and not analyzed.  This is as expected.
The buoyancy frequency data do not contain observations for the California site (CA-10082) where the sonde was reported missing/malfunctioning.
```{r}
# are all SITE_ID values in buoyancy frequency also present in dg?
bf.max %>% filter(!(SITE_ID %in% dg$site.id)) %>% # no, OR and AZ-10007
print(n= Inf)


# are all site.id values in dg also present in bf.max?
# Just CA site, as expected.
dg %>% filter(!(site.id %in% bf.max$SITE_ID)) %>% # no
  select(site.id, visit.no)


# dim(bf.max) # 1209, 3
# dim(dg) # 2369, 374

# Left join: retain all dg values, exclude non-matching bf values (i.e. OR and AZ)
dg <- left_join(dg, bf.max, by = c("site.id" = "SITE_ID", "visit.no" = "VISIT_NO"))  
# dim(dg) # 2369, 375, good!
```

The California site with the broken sonde has no bf data.  Nothing we can do about it.
```{r}
dg %>% filter(is.na(MAX.BF)) %>%
  select(site.id, visit.no)
```

Webb et al. used the 'surface' and 'bottom' water DO percent saturation and temperature as predictors, but didn't give more details on how these indices were calculated.  We will do something similar and define the 'shallowest' and 'deepest' measurements as 'surface' and 'bottom', respectively, but will use mg.l for dissolved oxygen.
```{r}
# o2 surface (s) and bottom (b)
o2.s.b <- 
temp.o2.2 %>% 
  group_by(SITE_ID, VISIT_NO) %>%
  slice(c(which.min(DEPTH), which.max(DEPTH))) %>% # min and max depth by group
  arrange(SITE_ID, VISIT_NO, DEPTH) %>%
    mutate(DEPTH = ifelse(row_number() == 1,
                        "surface",
                        "bottom")) %>%
  pivot_wider(id_cols = c(SITE_ID, VISIT_NO), 
              names_from = DEPTH, 
              values_from = c(TEMPERATURE.M, OXYGEN.M)) %>%
  rename(temp.surf = TEMPERATURE.M_surface,
         temp.bottom = TEMPERATURE.M_bottom,
         o2.surf = OXYGEN.M_surface,
         o2.bottom = OXYGEN.M_bottom)

o2.s.b

```

These calculations produced 8 site visits with at least one NA for surface/bottom temp/DO.  

```{r}
o2.s.b %>% filter(is.na(temp.surf) | is.na(temp.bottom) | is.na(o2.surf) | is.na(temp.bottom))
```

o2.surf at NLA17_FL-10029 is a case with no DO at shallowest depth, but good measurements below.  Replace with next shallowest value.
``` {r}
# Inspect raw data
temp.o2.2 %>% filter(SITE_ID == "NLA17_FL-10029", VISIT_NO == 1)

# update data
o2.s.b <- o2.s.b %>%
  mutate(o2.surf = replace(o2.surf, 
                           SITE_ID == "NLA17_FL-10029" & VISIT_NO == 1,
                           temp.o2 %>% filter(SITE_ID=="NLA17_FL-10029",
                                              VISIT_NO == 1,
                                              DEPTH == 1) %>%
                             select(OXYGEN) %>% pull()))

```
No bottom water DO or temp at NLA17_ID-10001, visit 1 due to probe malfunction.

```{r}
temp.o2.2 %>% filter(SITE_ID == "NLA17_ID-10001", VISIT_NO == 1)
```

No DO NLA17_ID-10084, visit 1 due to probe malfunction.

```{r}
temp.o2.2 %>% filter(SITE_ID == "NLA17_ID-10084", VISIT_NO == 1)
```

No deep DO or temp at NLA17_MI-10073, visit 1 becuase no measurement taken at deepst recorded depth.  Replace with next shallowest measurement. 

```{r}
# look at raw data
temp.o2.2 %>% filter(SITE_ID == "NLA17_MI-10073", VISIT_NO == 1)

# update aggregated data
o2.s.b <- o2.s.b %>%
  mutate(o2.bottom = replace(o2.bottom, 
                           SITE_ID == "NLA17_MI-10073" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_MI-10073",
                                              VISIT_NO == 1,
                                              DEPTH == 1.3) %>%
                             select(OXYGEN.M) %>% pull()),
         temp.bottom = replace(temp.bottom, 
                           SITE_ID == "NLA17_MI-10073" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_MI-10073",
                                              VISIT_NO == 1,
                                              DEPTH == 1.3) %>%
                             select(TEMPERATURE.M) %>% pull()))
```

No surface temp at NLA17_NE-10060, visit 1 becuase no measurement taken at shallowest depth (0m). Replace with next shallowest measurement (0.1m) 

```{r}
# look at raw data
temp.o2.2 %>% filter(SITE_ID == "NLA17_NE-10060", VISIT_NO == 1)

o2.s.b <- o2.s.b %>%
  mutate(temp.surf = replace(temp.surf, 
                           SITE_ID == "NLA17_NE-10060" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_NE-10060",
                                              VISIT_NO == 1,
                                              DEPTH == 0.1) %>%
                             select(TEMPERATURE.M) %>% pull()))
```


No bottom temp or O2 at NLA17_NH-10063, visit 1 becuase no measurement taken at greatest depth (8m). Replace with next deeptest measurement (7.5m) 

```{r}
# look at raw data
temp.o2.2 %>% filter(SITE_ID == "NLA17_NH-10063", VISIT_NO == 1)

o2.s.b <- o2.s.b %>%
  mutate(temp.bottom = replace(temp.bottom, 
                           SITE_ID == "NLA17_NH-10063" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_NH-10063",
                                              VISIT_NO == 1,
                                              DEPTH == 7.5) %>%
                             select(TEMPERATURE.M) %>% pull()),
         o2.bottom = replace(o2.bottom, 
                           SITE_ID == "NLA17_NH-10063" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_NH-10063",
                                              VISIT_NO == 1,
                                              DEPTH == 7.5) %>%
                             select(OXYGEN.M) %>% pull()))
```


No surface temp or O2 at NLA17_OR-10003, visit 1 becuase no measurement taken at shallowest depth (0m). Replace with next shallowest measurement (0.1m) 

```{r}
# look at raw data
temp.o2.2 %>% filter(SITE_ID == "NLA17_OR-10003", VISIT_NO == 1)

o2.s.b <- o2.s.b %>%
  mutate(temp.surf = replace(temp.surf, 
                           SITE_ID == "NLA17_OR-10003" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_OR-10003",
                                              VISIT_NO == 1,
                                              DEPTH == 0.1) %>%
                             select(TEMPERATURE.M) %>% pull()),
         o2.surf = replace(o2.surf, 
                           SITE_ID == "NLA17_OR-10003" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_OR-10003",
                                              VISIT_NO == 1,
                                              DEPTH == 0.1) %>%
                             select(OXYGEN.M) %>% pull()))
```

No bottom temp or O2 at NLA17_SD-10057, visit 1 becuase no measurement taken at deepest depth (4m). Replace with next deepest measurement (3m) 

```{r}
# look at raw data
temp.o2.2 %>% filter(SITE_ID == "NLA17_SD-10057", VISIT_NO == 1)

o2.s.b <- o2.s.b %>%
  mutate(temp.bottom = replace(temp.bottom, 
                           SITE_ID == "NLA17_SD-10057" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_SD-10057",
                                              VISIT_NO == 1,
                                              DEPTH == 3) %>%
                             select(TEMPERATURE.M) %>% pull()),
         o2.bottom = replace(o2.bottom, 
                           SITE_ID == "NLA17_SD-10057" & VISIT_NO == 1,
                           temp.o2.2 %>% filter(SITE_ID=="NLA17_SD-10057",
                                              VISIT_NO == 1,
                                              DEPTH == 3) %>%
                             select(OXYGEN.M) %>% pull()))
```


Only remainining missing values are observations where field crews noted sonde malfunctions.

```{r}
o2.s.b %>% filter(is.na(temp.surf) | is.na(temp.bottom) | is.na(o2.surf) | is.na(temp.bottom))
```


Merge bottom and surface DO and temperature with dg data.


```{r}
# are all SITE_ID values in o2 and temp data also present in dg?
o2.s.b %>% filter(!(SITE_ID %in% dg$site.id)) %>% # no, OR and AZ-10007
print(n= Inf)


# are all site.id values in dg also present in o2 and temp data?
# Just CA site, as expected.
dg %>% filter(!(site.id %in% o2.s.b$SITE_ID)) %>% # no
  select(site.id, visit.no)


# dim(o2.s.b) # 1209, 6
# dim(dg) # 2369, 375

# Left join: retain all dg values, exclude non-matching bf values (i.e. OR and AZ)
dg <- left_join(dg, o2.s.b, by = c("site.id" = "SITE_ID", "visit.no" = "VISIT_NO"))  
# dim(dg) # 2369, 379, good!
```



Write out final .RData object.
```{r}
save(dg, file = paste0(localPath, 
                       "/Environmental Protection Agency (EPA)/",
                       "ORD NLA17 Dissolved Gas - Documents/",
                       "inputData/dg.", Sys.Date(), ".RData"))
```



